{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# MANOAP: MicroSEC-Assisted NGS-Originating Arfifact Predictor\n",
    "# MANOSEP: MicroSEC And NGBoost Orchestrating Sequence Error Predictor\n",
    "\n",
    "# MicroSEC-based FFPE artifact predictor.\n",
    "# Necessary data are following.\n",
    "# A list of mutations described as genomic positions, saved as a tsv file.\n",
    "# Positions should be represented acccording to hg38 or hg 19.\n",
    "# Sample            Chr    Pos       Ref   Alt\n",
    "# Patient_1_tumor   chr1   2561609   T     A  \n",
    "\n",
    "# Get neighbor 400 bases around the mutation\n",
    "\n",
    "# search 40 bases from the genome\n",
    "# the mutated base must be matched\n",
    "# Homo_sapiens.GRCh38.dna.toplevel.fa\n",
    "# blat stand alone\n",
    "# scoring\n",
    "\n",
    "# search hairpin structure\n",
    "# maximum haipin length\n",
    "# complete match is necessary\n",
    "# 5' length\n",
    "# 3' length\n",
    "# C:G and A:T counts\n",
    "\n",
    "\n",
    "# Mutation format converter program will be added\n",
    "# From\n",
    "# Sample            Gene    mRNA_change\n",
    "# Patient_1_tumor   APC     NM_0000:c.111T>C  \n",
    "# To\n",
    "# Sample            Chr    Pos       Ref   Alt\n",
    "# Patient_1_tumor   chr1   2561609   T     A  \n",
    "                                                                                                                                                                                                                                                                                                                                                                                                                \n",
    "\n",
    "# https://www.bioconductor.org/packages/release/bioc/vignettes/ensembldb/inst/doc/coordinate-mapping.html\n",
    "# http://rest.ensembl.org/documentation/info/assembly_cdna\n",
    "\n",
    "https://blog.amedama.jp/entry/2017/12/18/005311\n",
    "\n",
    "https://blog.amedama.jp/entry/2018/07/23/084500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Seq import Seq\n",
    "from Bio import SeqIO\n",
    "from Bio import pairwise2\n",
    "from Bio.pairwise2 import format_alignment\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import subprocess, sys, os\n",
    "import copy\n",
    "import lightgbm as lgb\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input,Dense, Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "\n",
    "#os.system('for chr in `seq 1 22` X Y; do echo $chr; wget -qO- http://hgdownload.cse.ucsc.edu/goldenpath/hg38/chromosomes/chr$chr.fa.gz | gunzip -c - >> /mnt/HDD8TB/MicroSEC/source/hg38.fa; done')\n",
    "#os.system('for chr in `seq 1 22` X Y; do echo $chr; wget -qO- http://hgdownload.cse.ucsc.edu/goldenpath/hg19/chromosomes/chr$chr.fa.gz | gunzip -c - >> /mnt/HDD8TB/MicroSEC/source/hg19.fa; done')\n",
    "\n",
    "#pd.set_option('display.max_columns', 30)\n",
    "#pd.set_option('display.max_rows', 30)\n",
    "\n",
    "df = pd.read_excel(\"/mnt/HDD8TB/MicroSEC/source/MANOSEC_source.xlsx\")\n",
    "\n",
    "sort_order = ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10',\n",
    "              'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20',\n",
    "              'chr21', 'chr22', 'chrX', 'chrY']\n",
    "df.Chr = pd.Categorical(df.Chr, categories = sort_order)\n",
    "df.sort_values(by=['Chr'], inplace=True)\n",
    "df = df.reset_index()\n",
    "df['palindrome'] = \"\"\n",
    "df['search_seq_A'] = \"\"\n",
    "df['search_seq_B'] = \"\"\n",
    "df['search_seq_C'] = \"\"\n",
    "df['search_seq_D'] = \"\"\n",
    "df['rev_comp_seq'] = 0\n",
    "df['search_hairpin_A'] = \"\"\n",
    "df['search_hairpin_B'] = \"\"\n",
    "df['search_hairpin_C'] = \"\"\n",
    "df['search_hairpin_D'] = \"\"\n",
    "df['search_hairpin_E'] = \"\"\n",
    "df['possible_hairpin_A_1'] = 0\n",
    "df['possible_hairpin_A_2'] = 0\n",
    "df['possible_hairpin_A_3'] = 0\n",
    "df['possible_hairpin_A_4'] = 0\n",
    "df['possible_hairpin_A_5'] = 0\n",
    "df['possible_hairpin_A_6'] = 0\n",
    "df['possible_hairpin_B_1'] = 0\n",
    "df['possible_hairpin_B_2'] = 0\n",
    "df['possible_hairpin_B_3'] = 0\n",
    "df['possible_hairpin_B_4'] = 0\n",
    "df['possible_hairpin_B_5'] = 0\n",
    "df['possible_hairpin_B_6'] = 0\n",
    "df['possible_hairpin_C_1'] = 0\n",
    "df['possible_hairpin_C_2'] = 0\n",
    "df['possible_hairpin_C_3'] = 0\n",
    "df['possible_hairpin_C_4'] = 0\n",
    "df['possible_hairpin_C_5'] = 0\n",
    "df['possible_hairpin_C_6'] = 0\n",
    "df['possible_hairpin_D_1'] = 0\n",
    "df['possible_hairpin_D_2'] = 0\n",
    "df['possible_hairpin_D_3'] = 0\n",
    "df['possible_hairpin_D_4'] = 0\n",
    "df['possible_hairpin_D_5'] = 0\n",
    "df['possible_hairpin_D_6'] = 0\n",
    "df['possible_hairpin_E_1'] = 0\n",
    "df['possible_hairpin_E_2'] = 0\n",
    "df['possible_hairpin_E_3'] = 0\n",
    "df['possible_hairpin_E_4'] = 0\n",
    "df['possible_hairpin_E_5'] = 0\n",
    "df['possible_hairpin_E_6'] = 0\n",
    "df['score_A_20'] = 0\n",
    "df['score_A_25'] = 0\n",
    "df['score_A_30'] = 0\n",
    "df['score_A_35'] = 0\n",
    "df['score_A_40'] = 0\n",
    "df['score_A_45'] = 0\n",
    "df['score_A_50'] = 0\n",
    "df['score_A_55'] = 0\n",
    "df['score_A_60'] = 0\n",
    "df['score_B_20'] = 0\n",
    "df['score_B_25'] = 0\n",
    "df['score_B_30'] = 0\n",
    "df['score_B_35'] = 0\n",
    "df['score_B_40'] = 0\n",
    "df['score_B_45'] = 0\n",
    "df['score_B_50'] = 0\n",
    "df['score_B_55'] = 0\n",
    "df['score_B_60'] = 0\n",
    "df['score_C_20'] = 0\n",
    "df['score_C_25'] = 0\n",
    "df['score_C_30'] = 0\n",
    "df['score_C_35'] = 0\n",
    "df['score_C_40'] = 0\n",
    "df['score_C_45'] = 0\n",
    "df['score_C_50'] = 0\n",
    "df['score_C_55'] = 0\n",
    "df['score_C_60'] = 0\n",
    "df['score_D_20'] = 0\n",
    "df['score_D_25'] = 0\n",
    "df['score_D_30'] = 0\n",
    "df['score_D_35'] = 0\n",
    "df['score_D_40'] = 0\n",
    "df['score_D_45'] = 0\n",
    "df['score_D_50'] = 0\n",
    "df['score_D_55'] = 0\n",
    "df['score_D_60'] = 0\n",
    "df_working = copy.deepcopy(df)\n",
    "filename_BLAT = \"/mnt/HDD8TB/MicroSEC/source/MANOSEC_BLAT.fa\"\n",
    "f = open(filename_BLAT, 'w', encoding='UTF-8')\n",
    "records = SeqIO.parse('/mnt/HDD8TB/MicroSEC/source/hg38.fa', 'fasta')\n",
    "j = 0\n",
    "for record in records:\n",
    "    if df_working.shape[0] > 0:\n",
    "        if record.name == df_working.iloc[0].Chr:\n",
    "            df_tmp = df_working[df_working['Chr'] == df_working.iloc[0].Chr]\n",
    "            df_working = df_working[df_working['Chr'] != df_working.iloc[0].Chr]\n",
    "            for i in range(df_tmp.shape[0]):\n",
    "                if (j + 1) % 500 == 0:\n",
    "                    print(str(j + 1) + \" / \" + str(df.shape[0]))\n",
    "                ID = str(j)\n",
    "                pos_start_1 = df_tmp.iloc[i].Pos - 31\n",
    "                pos_start_2 = df_tmp.iloc[i].Pos + len(df_tmp.iloc[i].Ref) - 1\n",
    "                pos_end_1 = df_tmp.iloc[i].Pos - 1\n",
    "                pos_end_2 = df_tmp.iloc[i].Pos + len(df_tmp.iloc[i].Ref) + 29\n",
    "                seq_tmp = (str(record.seq[pos_start_1:pos_end_1]) + df_tmp.iloc[i].Alt + str(record.seq[pos_start_2:pos_end_2])).lower()\n",
    "                f.write('>' + ID + '\\n')\n",
    "                f.write(seq_tmp + '\\n')\n",
    "                df.loc[j, 'palindrome'] = (str(record.seq[pos_end_1 - 200:pos_end_1]) + df_tmp.iloc[i].Ref + str(record.seq[pos_start_2:pos_start_2 + 200])).lower()\n",
    "                df.loc[j, 'search_seq_A'] = (str(record.seq[pos_end_1 - 3:pos_end_1]) + df_tmp.iloc[i].Alt + str(record.seq[pos_start_2:pos_start_2 + 3])).upper()\n",
    "                df.loc[j, 'search_seq_B'] = (str(record.seq[pos_end_1 - 4:pos_end_1]) + df_tmp.iloc[i].Alt + str(record.seq[pos_start_2:pos_start_2 + 4])).upper()\n",
    "                df.loc[j, 'search_seq_C'] = (str(record.seq[pos_end_1 - 8:pos_end_1]) + df_tmp.iloc[i].Alt).upper()\n",
    "                df.loc[j, 'search_seq_D'] = (df_tmp.iloc[i].Alt + str(record.seq[pos_start_2:pos_start_2 + 8])).upper()\n",
    "                if str(Seq(df_tmp.iloc[i].Alt).reverse_complement()).upper() == df_tmp.iloc[i].Ref.upper():\n",
    "                    df.loc[j, 'rev_comp_seq'] = 1\n",
    "                df.loc[j, 'search_hairpin_A'] = (str(record.seq[pos_end_1 - 4:pos_end_1]) + df_tmp.iloc[i].Alt + str(record.seq[pos_start_2:pos_start_2 + 4])).upper()\n",
    "                df.loc[j, 'search_hairpin_B'] = (str(record.seq[pos_end_1 - 6:pos_end_1]) + df_tmp.iloc[i].Alt + str(record.seq[pos_start_2:pos_start_2 + 6])).upper()\n",
    "                df.loc[j, 'search_hairpin_C'] = (str(record.seq[pos_end_1 - 8:pos_end_1]) + df_tmp.iloc[i].Alt + str(record.seq[pos_start_2:pos_start_2 + 8])).upper()\n",
    "                df.loc[j, 'search_hairpin_D'] = (str(record.seq[pos_end_1 - 10:pos_end_1]) + df_tmp.iloc[i].Alt + str(record.seq[pos_start_2:pos_start_2 + 10])).upper()\n",
    "                df.loc[j, 'search_hairpin_E'] = (str(record.seq[pos_end_1 - 12:pos_end_1]) + df_tmp.iloc[i].Alt + str(record.seq[pos_start_2:pos_start_2 + 12])).upper()\n",
    "                j = j + 1\n",
    "print(str(j) + \" / \" + str(df.shape[0]))\n",
    "f.close()\n",
    "os.system('blat -stepSize=5 -repMatch=2253 -minScore=20 -minIdentity=0 /mnt/HDD8TB/MicroSEC/source/hg38.fa /mnt/HDD8TB/MicroSEC/source/MANOSEC_BLAT.fa /mnt/HDD8TB/MicroSEC/source/output.pslx -out=pslx -t=dna -q=dna')\n",
    "os.system('sed \"1,5d\" /mnt/HDD8TB/MicroSEC/source/output.pslx > /mnt/HDD8TB/MicroSEC/source/output.tsv')\n",
    "\n",
    "result_BLAT = pd.read_csv('/mnt/HDD8TB/MicroSEC/source/output.tsv', delimiter='\\t', header=None)\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    if (i + 1) % 500 == 0:\n",
    "        print(str(i + 1) + \" / \" + str(df.shape[0]))\n",
    "    df.loc[i, 'possible_hairpin_A_1'] = pairwise2.align.localms(df.loc[i,'palindrome'], str(Seq(df.loc[i,'search_hairpin_A']).reverse_complement()).lower(), 1, -1, -1, -1, score_only = True)\n",
    "    df.loc[i, 'possible_hairpin_A_2'] = pairwise2.align.localms(df.loc[i,'palindrome'], str(Seq(df.loc[i,'search_hairpin_A']).reverse_complement()).lower(), 1, -1, -2, -1, score_only = True)\n",
    "    df.loc[i, 'possible_hairpin_A_3'] = pairwise2.align.localms(df.loc[i,'palindrome'], str(Seq(df.loc[i,'search_hairpin_A']).reverse_complement()).lower(), 1, -2, -1, -1, score_only = True)\n",
    "    df.loc[i, 'possible_hairpin_A_4'] = pairwise2.align.localms(df.loc[i,'palindrome'], str(Seq(df.loc[i,'search_hairpin_A']).reverse_complement()).lower(), 1, -2, -2, -1, score_only = True)\n",
    "    df.loc[i, 'possible_hairpin_A_5'] = pairwise2.align.localms(df.loc[i,'palindrome'], str(Seq(df.loc[i,'search_hairpin_A']).reverse_complement()).lower(), 1, -3, -2, -1, score_only = True)\n",
    "    df.loc[i, 'possible_hairpin_A_6'] = pairwise2.align.localms(df.loc[i,'palindrome'], str(Seq(df.loc[i,'search_hairpin_A']).reverse_complement()).lower(), 1, -2, -3, -1, score_only = True)\n",
    "    df.loc[i, 'possible_hairpin_B_1'] = pairwise2.align.localms(df.loc[i,'palindrome'], str(Seq(df.loc[i,'search_hairpin_B']).reverse_complement()).lower(), 1, -1, -1, -1, score_only = True)\n",
    "    df.loc[i, 'possible_hairpin_B_2'] = pairwise2.align.localms(df.loc[i,'palindrome'], str(Seq(df.loc[i,'search_hairpin_B']).reverse_complement()).lower(), 1, -1, -2, -1, score_only = True)\n",
    "    df.loc[i, 'possible_hairpin_B_3'] = pairwise2.align.localms(df.loc[i,'palindrome'], str(Seq(df.loc[i,'search_hairpin_B']).reverse_complement()).lower(), 1, -2, -1, -1, score_only = True)\n",
    "    df.loc[i, 'possible_hairpin_B_4'] = pairwise2.align.localms(df.loc[i,'palindrome'], str(Seq(df.loc[i,'search_hairpin_B']).reverse_complement()).lower(), 1, -2, -2, -1, score_only = True)\n",
    "    df.loc[i, 'possible_hairpin_B_5'] = pairwise2.align.localms(df.loc[i,'palindrome'], str(Seq(df.loc[i,'search_hairpin_B']).reverse_complement()).lower(), 1, -3, -2, -1, score_only = True)\n",
    "    df.loc[i, 'possible_hairpin_B_6'] = pairwise2.align.localms(df.loc[i,'palindrome'], str(Seq(df.loc[i,'search_hairpin_B']).reverse_complement()).lower(), 1, -2, -3, -1, score_only = True)\n",
    "    df.loc[i, 'possible_hairpin_C_1'] = pairwise2.align.localms(df.loc[i,'palindrome'], str(Seq(df.loc[i,'search_hairpin_C']).reverse_complement()).lower(), 1, -1, -1, -1, score_only = True)\n",
    "    df.loc[i, 'possible_hairpin_C_2'] = pairwise2.align.localms(df.loc[i,'palindrome'], str(Seq(df.loc[i,'search_hairpin_C']).reverse_complement()).lower(), 1, -1, -2, -1, score_only = True)\n",
    "    df.loc[i, 'possible_hairpin_C_3'] = pairwise2.align.localms(df.loc[i,'palindrome'], str(Seq(df.loc[i,'search_hairpin_C']).reverse_complement()).lower(), 1, -2, -1, -1, score_only = True)\n",
    "    df.loc[i, 'possible_hairpin_C_4'] = pairwise2.align.localms(df.loc[i,'palindrome'], str(Seq(df.loc[i,'search_hairpin_C']).reverse_complement()).lower(), 1, -2, -2, -1, score_only = True)\n",
    "    df.loc[i, 'possible_hairpin_C_5'] = pairwise2.align.localms(df.loc[i,'palindrome'], str(Seq(df.loc[i,'search_hairpin_C']).reverse_complement()).lower(), 1, -3, -2, -1, score_only = True)\n",
    "    df.loc[i, 'possible_hairpin_C_6'] = pairwise2.align.localms(df.loc[i,'palindrome'], str(Seq(df.loc[i,'search_hairpin_C']).reverse_complement()).lower(), 1, -2, -3, -1, score_only = True)\n",
    "    df.loc[i, 'possible_hairpin_D_1'] = pairwise2.align.localms(df.loc[i,'palindrome'], str(Seq(df.loc[i,'search_hairpin_D']).reverse_complement()).lower(), 1, -1, -1, -1, score_only = True)\n",
    "    df.loc[i, 'possible_hairpin_D_2'] = pairwise2.align.localms(df.loc[i,'palindrome'], str(Seq(df.loc[i,'search_hairpin_D']).reverse_complement()).lower(), 1, -1, -2, -1, score_only = True)\n",
    "    df.loc[i, 'possible_hairpin_D_3'] = pairwise2.align.localms(df.loc[i,'palindrome'], str(Seq(df.loc[i,'search_hairpin_D']).reverse_complement()).lower(), 1, -2, -1, -1, score_only = True)\n",
    "    df.loc[i, 'possible_hairpin_D_4'] = pairwise2.align.localms(df.loc[i,'palindrome'], str(Seq(df.loc[i,'search_hairpin_D']).reverse_complement()).lower(), 1, -2, -2, -1, score_only = True)\n",
    "    df.loc[i, 'possible_hairpin_D_5'] = pairwise2.align.localms(df.loc[i,'palindrome'], str(Seq(df.loc[i,'search_hairpin_D']).reverse_complement()).lower(), 1, -3, -2, -1, score_only = True)\n",
    "    df.loc[i, 'possible_hairpin_D_6'] = pairwise2.align.localms(df.loc[i,'palindrome'], str(Seq(df.loc[i,'search_hairpin_D']).reverse_complement()).lower(), 1, -2, -3, -1, score_only = True)\n",
    "    df.loc[i, 'possible_hairpin_E_1'] = pairwise2.align.localms(df.loc[i,'palindrome'], str(Seq(df.loc[i,'search_hairpin_E']).reverse_complement()).lower(), 1, -1, -1, -1, score_only = True)\n",
    "    df.loc[i, 'possible_hairpin_E_2'] = pairwise2.align.localms(df.loc[i,'palindrome'], str(Seq(df.loc[i,'search_hairpin_E']).reverse_complement()).lower(), 1, -1, -2, -1, score_only = True)\n",
    "    df.loc[i, 'possible_hairpin_E_3'] = pairwise2.align.localms(df.loc[i,'palindrome'], str(Seq(df.loc[i,'search_hairpin_E']).reverse_complement()).lower(), 1, -2, -1, -1, score_only = True)\n",
    "    df.loc[i, 'possible_hairpin_E_4'] = pairwise2.align.localms(df.loc[i,'palindrome'], str(Seq(df.loc[i,'search_hairpin_E']).reverse_complement()).lower(), 1, -2, -2, -1, score_only = True)\n",
    "    df.loc[i, 'possible_hairpin_E_5'] = pairwise2.align.localms(df.loc[i,'palindrome'], str(Seq(df.loc[i,'search_hairpin_E']).reverse_complement()).lower(), 1, -3, -2, -1, score_only = True)\n",
    "    df.loc[i, 'possible_hairpin_E_6'] = pairwise2.align.localms(df.loc[i,'palindrome'], str(Seq(df.loc[i,'search_hairpin_E']).reverse_complement()).lower(), 1, -2, -3, -1, score_only = True)\n",
    "    tmp_BLAT = result_BLAT[result_BLAT[9] == i]\n",
    "    tmp_BLAT = tmp_BLAT[tmp_BLAT[22].str.contains(df.loc[i, 'search_seq_A'].lower())]\n",
    "    tmp_BLAT = tmp_BLAT[tmp_BLAT[7] < 10]\n",
    "    if tmp_BLAT.shape[0] > 0:\n",
    "        for j in range(tmp_BLAT.shape[0]):\n",
    "            tmp_score = tmp_BLAT.iloc[j,12]\n",
    "            if tmp_score >= 20:\n",
    "                df.loc[i, 'score_A_20'] = df.loc[i, 'score_A_20'] + 1\n",
    "            if tmp_score >= 25:\n",
    "                df.loc[i, 'score_A_25'] = df.loc[i, 'score_A_25'] + 1\n",
    "            if tmp_score >= 30:\n",
    "                df.loc[i, 'score_A_30'] = df.loc[i, 'score_A_30'] + 1\n",
    "            if tmp_score >= 35:\n",
    "                df.loc[i, 'score_A_35'] = df.loc[i, 'score_A_35'] + 1\n",
    "            if tmp_score >= 40:\n",
    "                df.loc[i, 'score_A_40'] = df.loc[i, 'score_A_40'] + 1\n",
    "            if tmp_score >= 45:\n",
    "                df.loc[i, 'score_A_45'] = df.loc[i, 'score_A_45'] + 1\n",
    "            if tmp_score >= 50:\n",
    "                df.loc[i, 'score_A_50'] = df.loc[i, 'score_A_50'] + 1\n",
    "            if tmp_score >= 55:\n",
    "                df.loc[i, 'score_A_55'] = df.loc[i, 'score_A_55'] + 1\n",
    "            if tmp_score >= 60:\n",
    "                df.loc[i, 'score_A_60'] = df.loc[i, 'score_A_60'] + 1\n",
    "    tmp_BLAT = result_BLAT[result_BLAT[9] == i]\n",
    "    tmp_BLAT = tmp_BLAT[tmp_BLAT[22].str.contains(df.loc[i, 'search_seq_B'].lower())]\n",
    "    tmp_BLAT = tmp_BLAT[tmp_BLAT[7] < 10]\n",
    "    if tmp_BLAT.shape[0] > 0:\n",
    "        for j in range(tmp_BLAT.shape[0]):\n",
    "            tmp_score = tmp_BLAT.iloc[j,12]\n",
    "            if tmp_score >= 20:\n",
    "                df.loc[i, 'score_B_20'] = df.loc[i, 'score_B_20'] + 1\n",
    "            if tmp_score >= 25:\n",
    "                df.loc[i, 'score_B_25'] = df.loc[i, 'score_B_25'] + 1\n",
    "            if tmp_score >= 30:\n",
    "                df.loc[i, 'score_B_30'] = df.loc[i, 'score_B_30'] + 1\n",
    "            if tmp_score >= 35:\n",
    "                df.loc[i, 'score_B_35'] = df.loc[i, 'score_B_35'] + 1\n",
    "            if tmp_score >= 40:\n",
    "                df.loc[i, 'score_B_40'] = df.loc[i, 'score_B_40'] + 1\n",
    "            if tmp_score >= 45:\n",
    "                df.loc[i, 'score_B_45'] = df.loc[i, 'score_B_45'] + 1\n",
    "            if tmp_score >= 50:\n",
    "                df.loc[i, 'score_B_50'] = df.loc[i, 'score_B_50'] + 1\n",
    "            if tmp_score >= 55:\n",
    "                df.loc[i, 'score_B_55'] = df.loc[i, 'score_B_55'] + 1\n",
    "            if tmp_score >= 60:\n",
    "                df.loc[i, 'score_B_60'] = df.loc[i, 'score_B_60'] + 1\n",
    "\n",
    "    tmp_BLAT = result_BLAT[result_BLAT[9] == i]\n",
    "    tmp_BLAT = tmp_BLAT[tmp_BLAT[22].str.contains(df.loc[i, 'search_seq_C'].lower())]\n",
    "    tmp_BLAT = tmp_BLAT[tmp_BLAT[7] < 10]\n",
    "    if tmp_BLAT.shape[0] > 0:\n",
    "        for j in range(tmp_BLAT.shape[0]):\n",
    "            tmp_score = tmp_BLAT.iloc[j,12]\n",
    "            if tmp_score >= 20:\n",
    "                df.loc[i, 'score_C_20'] = df.loc[i, 'score_C_20'] + 1\n",
    "            if tmp_score >= 25:\n",
    "                df.loc[i, 'score_C_25'] = df.loc[i, 'score_C_25'] + 1\n",
    "            if tmp_score >= 30:\n",
    "                df.loc[i, 'score_C_30'] = df.loc[i, 'score_C_30'] + 1\n",
    "            if tmp_score >= 35:\n",
    "                df.loc[i, 'score_C_35'] = df.loc[i, 'score_C_35'] + 1\n",
    "            if tmp_score >= 40:\n",
    "                df.loc[i, 'score_C_40'] = df.loc[i, 'score_C_40'] + 1\n",
    "            if tmp_score >= 45:\n",
    "                df.loc[i, 'score_C_45'] = df.loc[i, 'score_C_45'] + 1\n",
    "            if tmp_score >= 50:\n",
    "                df.loc[i, 'score_C_50'] = df.loc[i, 'score_C_50'] + 1\n",
    "            if tmp_score >= 55:\n",
    "                df.loc[i, 'score_C_55'] = df.loc[i, 'score_C_55'] + 1\n",
    "            if tmp_score >= 60:\n",
    "                df.loc[i, 'score_C_60'] = df.loc[i, 'score_C_60'] + 1\n",
    "\n",
    "    tmp_BLAT = result_BLAT[result_BLAT[9] == i]\n",
    "    tmp_BLAT = tmp_BLAT[tmp_BLAT[22].str.contains(df.loc[i, 'search_seq_D'].lower())]\n",
    "    tmp_BLAT = tmp_BLAT[tmp_BLAT[7] < 10]\n",
    "    if tmp_BLAT.shape[0] > 0:\n",
    "        for j in range(tmp_BLAT.shape[0]):\n",
    "            tmp_score = tmp_BLAT.iloc[j,12]\n",
    "            if tmp_score >= 20:\n",
    "                df.loc[i, 'score_D_20'] = df.loc[i, 'score_D_20'] + 1\n",
    "            if tmp_score >= 25:\n",
    "                df.loc[i, 'score_D_25'] = df.loc[i, 'score_D_25'] + 1\n",
    "            if tmp_score >= 30:\n",
    "                df.loc[i, 'score_D_30'] = df.loc[i, 'score_D_30'] + 1\n",
    "            if tmp_score >= 35:\n",
    "                df.loc[i, 'score_D_35'] = df.loc[i, 'score_D_35'] + 1\n",
    "            if tmp_score >= 40:\n",
    "                df.loc[i, 'score_D_40'] = df.loc[i, 'score_D_40'] + 1\n",
    "            if tmp_score >= 45:\n",
    "                df.loc[i, 'score_D_45'] = df.loc[i, 'score_D_45'] + 1\n",
    "            if tmp_score >= 50:\n",
    "                df.loc[i, 'score_D_50'] = df.loc[i, 'score_D_50'] + 1\n",
    "            if tmp_score >= 55:\n",
    "                df.loc[i, 'score_D_55'] = df.loc[i, 'score_D_55'] + 1\n",
    "            if tmp_score >= 60:\n",
    "                df.loc[i, 'score_D_60'] = df.loc[i, 'score_D_60'] + 1\n",
    "\n",
    "print(str(i + 1) + \" / \" + str(df.shape[0]))\n",
    "\n",
    "df.to_excel('/mnt/HDD8TB/MicroSEC/source/MANOSEC_processed.xlsx')\n",
    "\n",
    "X = df.loc[:, (\"%Alt\", \"rev_comp_seq\",\n",
    "               \"possible_hairpin_A_1\", \"possible_hairpin_A_2\", \"possible_hairpin_A_3\", \"possible_hairpin_A_4\", \"possible_hairpin_A_5\", \"possible_hairpin_A_6\",\n",
    "               \"possible_hairpin_B_1\", \"possible_hairpin_B_2\", \"possible_hairpin_B_3\", \"possible_hairpin_B_4\", \"possible_hairpin_B_5\", \"possible_hairpin_B_6\",\n",
    "               \"possible_hairpin_C_1\", \"possible_hairpin_C_2\", \"possible_hairpin_C_3\", \"possible_hairpin_C_4\", \"possible_hairpin_C_5\", \"possible_hairpin_C_6\",\n",
    "               \"possible_hairpin_D_1\", \"possible_hairpin_D_2\", \"possible_hairpin_D_3\", \"possible_hairpin_D_4\", \"possible_hairpin_D_5\", \"possible_hairpin_D_6\",\n",
    "               \"possible_hairpin_E_1\", \"possible_hairpin_E_2\", \"possible_hairpin_E_3\", \"possible_hairpin_E_4\", \"possible_hairpin_E_5\", \"possible_hairpin_E_6\",\n",
    "               \"score_A_20\", \"score_A_25\", \"score_A_30\", \"score_A_35\", \"score_A_40\", \"score_A_45\", \"score_A_50\", \"score_A_55\", \"score_A_60\",\n",
    "               \"score_A_20\", \"score_B_25\", \"score_B_30\", \"score_B_35\", \"score_B_40\", \"score_B_45\", \"score_B_50\", \"score_B_55\", \"score_B_60\",\n",
    "               \"score_C_20\", \"score_C_25\", \"score_C_30\", \"score_C_35\", \"score_C_40\", \"score_C_45\", \"score_C_50\", \"score_C_55\", \"score_C_60\",\n",
    "               \"score_D_20\", \"score_D_25\", \"score_D_30\", \"score_D_35\", \"score_D_40\", \"score_D_45\", \"score_D_50\", \"score_D_55\", \"score_D_60\",\n",
    "              )]\n",
    "X[\"SNV\"] = df.loc[:, (\"Mut_type\")].str.contains(\"snv\").astype(int)\n",
    "X[\"DEL\"] = df.loc[:, (\"Mut_type\")].str.contains(\"del\").astype(int)\n",
    "X[\"INS\"] = df.loc[:, (\"Mut_type\")].str.contains(\"ins\").astype(int)\n",
    "X[\"bases\"] = df.loc[:, (\"Mut_type\")].str.split(\"-\", expand=True)[0].astype(int)\n",
    "\n",
    "y = (df.loc[:, \"msec_filter_1234\"]).astype(int)\n",
    "\n",
    "\n",
    "###########################################\n",
    "\n",
    "df_MSK = pd.read_excel(\"/mnt/HDD8TB/MicroSEC/source/mutation_MSK.xlsx\")\n",
    "\n",
    "sort_order = ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10',\n",
    "              'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20',\n",
    "              'chr21', 'chr22', 'chrX', 'chrY']\n",
    "df_MSK.Chr = pd.Categorical(df_MSK.Chr, categories = sort_order)\n",
    "df_MSK.sort_values(by=['Chr'], inplace=True)\n",
    "df_MSK = df_MSK.reset_index()\n",
    "df_MSK['palindrome'] = \"\"\n",
    "df_MSK['search_seq_A'] = \"\"\n",
    "df_MSK['search_seq_B'] = \"\"\n",
    "df_MSK['search_seq_C'] = \"\"\n",
    "df_MSK['search_seq_D'] = \"\"\n",
    "df_MSK['rev_comp_seq'] = 0\n",
    "df_MSK['search_hairpin_A'] = \"\"\n",
    "df_MSK['search_hairpin_B'] = \"\"\n",
    "df_MSK['search_hairpin_C'] = \"\"\n",
    "df_MSK['search_hairpin_D'] = \"\"\n",
    "df_MSK['search_hairpin_E'] = \"\"\n",
    "df_MSK['possible_hairpin_A_1'] = 0\n",
    "df_MSK['possible_hairpin_A_2'] = 0\n",
    "df_MSK['possible_hairpin_A_3'] = 0\n",
    "df_MSK['possible_hairpin_A_4'] = 0\n",
    "df_MSK['possible_hairpin_A_5'] = 0\n",
    "df_MSK['possible_hairpin_A_6'] = 0\n",
    "df_MSK['possible_hairpin_B_1'] = 0\n",
    "df_MSK['possible_hairpin_B_2'] = 0\n",
    "df_MSK['possible_hairpin_B_3'] = 0\n",
    "df_MSK['possible_hairpin_B_4'] = 0\n",
    "df_MSK['possible_hairpin_B_5'] = 0\n",
    "df_MSK['possible_hairpin_B_6'] = 0\n",
    "df_MSK['possible_hairpin_C_1'] = 0\n",
    "df_MSK['possible_hairpin_C_2'] = 0\n",
    "df_MSK['possible_hairpin_C_3'] = 0\n",
    "df_MSK['possible_hairpin_C_4'] = 0\n",
    "df_MSK['possible_hairpin_C_5'] = 0\n",
    "df_MSK['possible_hairpin_C_6'] = 0\n",
    "df_MSK['possible_hairpin_D_1'] = 0\n",
    "df_MSK['possible_hairpin_D_2'] = 0\n",
    "df_MSK['possible_hairpin_D_3'] = 0\n",
    "df_MSK['possible_hairpin_D_4'] = 0\n",
    "df_MSK['possible_hairpin_D_5'] = 0\n",
    "df_MSK['possible_hairpin_D_6'] = 0\n",
    "df_MSK['possible_hairpin_E_1'] = 0\n",
    "df_MSK['possible_hairpin_E_2'] = 0\n",
    "df_MSK['possible_hairpin_E_3'] = 0\n",
    "df_MSK['possible_hairpin_E_4'] = 0\n",
    "df_MSK['possible_hairpin_E_5'] = 0\n",
    "df_MSK['possible_hairpin_E_6'] = 0\n",
    "df_MSK['score_A_20'] = 0\n",
    "df_MSK['score_A_25'] = 0\n",
    "df_MSK['score_A_30'] = 0\n",
    "df_MSK['score_A_35'] = 0\n",
    "df_MSK['score_A_40'] = 0\n",
    "df_MSK['score_A_45'] = 0\n",
    "df_MSK['score_A_50'] = 0\n",
    "df_MSK['score_A_55'] = 0\n",
    "df_MSK['score_A_60'] = 0\n",
    "df_MSK['score_B_20'] = 0\n",
    "df_MSK['score_B_25'] = 0\n",
    "df_MSK['score_B_30'] = 0\n",
    "df_MSK['score_B_35'] = 0\n",
    "df_MSK['score_B_40'] = 0\n",
    "df_MSK['score_B_45'] = 0\n",
    "df_MSK['score_B_50'] = 0\n",
    "df_MSK['score_B_55'] = 0\n",
    "df_MSK['score_B_60'] = 0\n",
    "df_MSK['score_C_20'] = 0\n",
    "df_MSK['score_C_25'] = 0\n",
    "df_MSK['score_C_30'] = 0\n",
    "df_MSK['score_C_35'] = 0\n",
    "df_MSK['score_C_40'] = 0\n",
    "df_MSK['score_C_45'] = 0\n",
    "df_MSK['score_C_50'] = 0\n",
    "df_MSK['score_C_55'] = 0\n",
    "df_MSK['score_C_60'] = 0\n",
    "df_MSK['score_D_20'] = 0\n",
    "df_MSK['score_D_25'] = 0\n",
    "df_MSK['score_D_30'] = 0\n",
    "df_MSK['score_D_35'] = 0\n",
    "df_MSK['score_D_40'] = 0\n",
    "df_MSK['score_D_45'] = 0\n",
    "df_MSK['score_D_50'] = 0\n",
    "df_MSK['score_D_55'] = 0\n",
    "df_MSK['score_D_60'] = 0\n",
    "\n",
    "df_MSK_working = copy.deepcopy(df_MSK)\n",
    "filename_BLAT = \"/mnt/HDD8TB/MicroSEC/source/MANOSEC_BLAT_MSK.fa\"\n",
    "f = open(filename_BLAT, 'w', encoding='UTF-8')\n",
    "records_MSK = SeqIO.parse('/mnt/HDD8TB/MicroSEC/source/hg19.fa', 'fasta')\n",
    "j = 0\n",
    "for record in records_MSK:\n",
    "    if df_MSK_working.shape[0] > 0:\n",
    "        if record.name == df_MSK_working.iloc[0].Chr:\n",
    "            df_MSK_tmp = df_MSK_working[df_MSK_working['Chr'] == df_MSK_working.iloc[0].Chr]\n",
    "            df_MSK_working = df_MSK_working[df_MSK_working['Chr'] != df_MSK_working.iloc[0].Chr]\n",
    "            for i in range(df_MSK_tmp.shape[0]):\n",
    "                if (j + 1) % 500 == 0:\n",
    "                    print(str(j + 1) + \" / \" + str(df_MSK.shape[0]))\n",
    "                ID = str(j)\n",
    "                pos_start_1 = df_MSK_tmp.iloc[i].Pos - 31\n",
    "                pos_start_2 = df_MSK_tmp.iloc[i].Pos + len(df_MSK_tmp.iloc[i].Ref) - 1\n",
    "                pos_end_1 = df_MSK_tmp.iloc[i].Pos - 1\n",
    "                pos_end_2 = df_MSK_tmp.iloc[i].Pos + len(df_MSK_tmp.iloc[i].Ref) + 29\n",
    "                seq_tmp = (str(record.seq[pos_start_1:pos_end_1]) + df_MSK_tmp.iloc[i].Alt + str(record.seq[pos_start_2:pos_end_2])).lower()\n",
    "                f.write('>' + ID + '\\n')\n",
    "                f.write(seq_tmp + '\\n')\n",
    "                df_MSK.loc[j, 'palindrome'] = (str(record.seq[pos_end_1 - 200:pos_end_1]) + df_MSK_tmp.iloc[i].Ref + str(record.seq[pos_start_2:pos_start_2 + 200])).lower()\n",
    "                df_MSK.loc[j, 'search_seq_A'] = (str(record.seq[pos_end_1 - 3:pos_end_1]) + df_MSK_tmp.iloc[i].Alt + str(record.seq[pos_start_2:pos_start_2 + 3])).upper()\n",
    "                df_MSK.loc[j, 'search_seq_B'] = (str(record.seq[pos_end_1 - 4:pos_end_1]) + df_MSK_tmp.iloc[i].Alt + str(record.seq[pos_start_2:pos_start_2 + 4])).upper()\n",
    "                df_MSK.loc[j, 'search_seq_C'] = (str(record.seq[pos_end_1 - 8:pos_end_1]) + df_MSK_tmp.iloc[i].Alt).upper()\n",
    "                df_MSK.loc[j, 'search_seq_D'] = (df_MSK_tmp.iloc[i].Alt + str(record.seq[pos_start_2:pos_start_2 + 8])).upper()\n",
    "                if str(Seq(df_MSK_tmp.iloc[i].Alt).reverse_complement()).upper() == df_MSK_tmp.iloc[i].Ref.upper():\n",
    "                    df_MSK.loc[j, 'rev_comp_seq'] = 1\n",
    "                df_MSK.loc[j, 'search_hairpin_A'] = (str(record.seq[pos_end_1 - 4:pos_end_1]) + df_MSK_tmp.iloc[i].Alt + str(record.seq[pos_start_2:pos_start_2 + 4])).upper()\n",
    "                df_MSK.loc[j, 'search_hairpin_B'] = (str(record.seq[pos_end_1 - 6:pos_end_1]) + df_MSK_tmp.iloc[i].Alt + str(record.seq[pos_start_2:pos_start_2 + 6])).upper()\n",
    "                df_MSK.loc[j, 'search_hairpin_C'] = (str(record.seq[pos_end_1 - 8:pos_end_1]) + df_MSK_tmp.iloc[i].Alt + str(record.seq[pos_start_2:pos_start_2 + 8])).upper()\n",
    "                df_MSK.loc[j, 'search_hairpin_D'] = (str(record.seq[pos_end_1 - 10:pos_end_1]) + df_MSK_tmp.iloc[i].Alt + str(record.seq[pos_start_2:pos_start_2 + 10])).upper()\n",
    "                df_MSK.loc[j, 'search_hairpin_E'] = (str(record.seq[pos_end_1 - 12:pos_end_1]) + df_MSK_tmp.iloc[i].Alt + str(record.seq[pos_start_2:pos_start_2 + 12])).upper()\n",
    "\n",
    "                j = j + 1\n",
    "print(str(j) + \" / \" + str(df_MSK.shape[0]))\n",
    "f.close()\n",
    "os.system('blat -stepSize=5 -repMatch=2253 -minScore=20 -minIdentity=0 /mnt/HDD8TB/MicroSEC/source/hg19.fa /mnt/HDD8TB/MicroSEC/source/MANOSEC_BLAT_MSK.fa /mnt/HDD8TB/MicroSEC/source/output_MSK.pslx -out=pslx -t=dna -q=dna')\n",
    "os.system('sed \"1,5d\" /mnt/HDD8TB/MicroSEC/source/output_MSK.pslx > /mnt/HDD8TB/MicroSEC/source/output_MSK.tsv')\n",
    "\n",
    "result_BLAT_MSK = pd.read_csv('/mnt/HDD8TB/MicroSEC/source/output_MSK.tsv', delimiter='\\t', header=None)\n",
    "\n",
    "for i in range(df_MSK.shape[0]):\n",
    "    if (i + 1) % 500 == 0:\n",
    "        print(str(i + 1) + \" / \" + str(df_MSK.shape[0]))\n",
    "    df_MSK.loc[i, 'possible_hairpin_A_1'] = pairwise2.align.localms(df_MSK.loc[i,'palindrome'], str(Seq(df_MSK.loc[i,'search_hairpin_A']).reverse_complement()).lower(), 1, -1, -1, -1, score_only = True)\n",
    "    df_MSK.loc[i, 'possible_hairpin_A_2'] = pairwise2.align.localms(df_MSK.loc[i,'palindrome'], str(Seq(df_MSK.loc[i,'search_hairpin_A']).reverse_complement()).lower(), 1, -1, -2, -1, score_only = True)\n",
    "    df_MSK.loc[i, 'possible_hairpin_A_3'] = pairwise2.align.localms(df_MSK.loc[i,'palindrome'], str(Seq(df_MSK.loc[i,'search_hairpin_A']).reverse_complement()).lower(), 1, -2, -1, -1, score_only = True)\n",
    "    df_MSK.loc[i, 'possible_hairpin_A_4'] = pairwise2.align.localms(df_MSK.loc[i,'palindrome'], str(Seq(df_MSK.loc[i,'search_hairpin_A']).reverse_complement()).lower(), 1, -2, -2, -1, score_only = True)\n",
    "    df_MSK.loc[i, 'possible_hairpin_A_5'] = pairwise2.align.localms(df_MSK.loc[i,'palindrome'], str(Seq(df_MSK.loc[i,'search_hairpin_A']).reverse_complement()).lower(), 1, -3, -2, -1, score_only = True)\n",
    "    df_MSK.loc[i, 'possible_hairpin_A_6'] = pairwise2.align.localms(df_MSK.loc[i,'palindrome'], str(Seq(df_MSK.loc[i,'search_hairpin_A']).reverse_complement()).lower(), 1, -2, -3, -1, score_only = True)\n",
    "    df_MSK.loc[i, 'possible_hairpin_B_1'] = pairwise2.align.localms(df_MSK.loc[i,'palindrome'], str(Seq(df_MSK.loc[i,'search_hairpin_B']).reverse_complement()).lower(), 1, -1, -1, -1, score_only = True)\n",
    "    df_MSK.loc[i, 'possible_hairpin_B_2'] = pairwise2.align.localms(df_MSK.loc[i,'palindrome'], str(Seq(df_MSK.loc[i,'search_hairpin_B']).reverse_complement()).lower(), 1, -1, -2, -1, score_only = True)\n",
    "    df_MSK.loc[i, 'possible_hairpin_B_3'] = pairwise2.align.localms(df_MSK.loc[i,'palindrome'], str(Seq(df_MSK.loc[i,'search_hairpin_B']).reverse_complement()).lower(), 1, -2, -1, -1, score_only = True)\n",
    "    df_MSK.loc[i, 'possible_hairpin_B_4'] = pairwise2.align.localms(df_MSK.loc[i,'palindrome'], str(Seq(df_MSK.loc[i,'search_hairpin_B']).reverse_complement()).lower(), 1, -2, -2, -1, score_only = True)\n",
    "    df_MSK.loc[i, 'possible_hairpin_B_5'] = pairwise2.align.localms(df_MSK.loc[i,'palindrome'], str(Seq(df_MSK.loc[i,'search_hairpin_B']).reverse_complement()).lower(), 1, -3, -2, -1, score_only = True)\n",
    "    df_MSK.loc[i, 'possible_hairpin_B_6'] = pairwise2.align.localms(df_MSK.loc[i,'palindrome'], str(Seq(df_MSK.loc[i,'search_hairpin_B']).reverse_complement()).lower(), 1, -2, -3, -1, score_only = True)\n",
    "    df_MSK.loc[i, 'possible_hairpin_C_1'] = pairwise2.align.localms(df_MSK.loc[i,'palindrome'], str(Seq(df_MSK.loc[i,'search_hairpin_C']).reverse_complement()).lower(), 1, -1, -1, -1, score_only = True)\n",
    "    df_MSK.loc[i, 'possible_hairpin_C_2'] = pairwise2.align.localms(df_MSK.loc[i,'palindrome'], str(Seq(df_MSK.loc[i,'search_hairpin_C']).reverse_complement()).lower(), 1, -1, -2, -1, score_only = True)\n",
    "    df_MSK.loc[i, 'possible_hairpin_C_3'] = pairwise2.align.localms(df_MSK.loc[i,'palindrome'], str(Seq(df_MSK.loc[i,'search_hairpin_C']).reverse_complement()).lower(), 1, -2, -1, -1, score_only = True)\n",
    "    df_MSK.loc[i, 'possible_hairpin_C_4'] = pairwise2.align.localms(df_MSK.loc[i,'palindrome'], str(Seq(df_MSK.loc[i,'search_hairpin_C']).reverse_complement()).lower(), 1, -2, -2, -1, score_only = True)\n",
    "    df_MSK.loc[i, 'possible_hairpin_C_5'] = pairwise2.align.localms(df_MSK.loc[i,'palindrome'], str(Seq(df_MSK.loc[i,'search_hairpin_C']).reverse_complement()).lower(), 1, -3, -2, -1, score_only = True)\n",
    "    df_MSK.loc[i, 'possible_hairpin_C_6'] = pairwise2.align.localms(df_MSK.loc[i,'palindrome'], str(Seq(df_MSK.loc[i,'search_hairpin_C']).reverse_complement()).lower(), 1, -2, -3, -1, score_only = True)\n",
    "    df_MSK.loc[i, 'possible_hairpin_D_1'] = pairwise2.align.localms(df_MSK.loc[i,'palindrome'], str(Seq(df_MSK.loc[i,'search_hairpin_D']).reverse_complement()).lower(), 1, -1, -1, -1, score_only = True)\n",
    "    df_MSK.loc[i, 'possible_hairpin_D_2'] = pairwise2.align.localms(df_MSK.loc[i,'palindrome'], str(Seq(df_MSK.loc[i,'search_hairpin_D']).reverse_complement()).lower(), 1, -1, -2, -1, score_only = True)\n",
    "    df_MSK.loc[i, 'possible_hairpin_D_3'] = pairwise2.align.localms(df_MSK.loc[i,'palindrome'], str(Seq(df_MSK.loc[i,'search_hairpin_D']).reverse_complement()).lower(), 1, -2, -1, -1, score_only = True)\n",
    "    df_MSK.loc[i, 'possible_hairpin_D_4'] = pairwise2.align.localms(df_MSK.loc[i,'palindrome'], str(Seq(df_MSK.loc[i,'search_hairpin_D']).reverse_complement()).lower(), 1, -2, -2, -1, score_only = True)\n",
    "    df_MSK.loc[i, 'possible_hairpin_D_5'] = pairwise2.align.localms(df_MSK.loc[i,'palindrome'], str(Seq(df_MSK.loc[i,'search_hairpin_D']).reverse_complement()).lower(), 1, -3, -2, -1, score_only = True)\n",
    "    df_MSK.loc[i, 'possible_hairpin_D_6'] = pairwise2.align.localms(df_MSK.loc[i,'palindrome'], str(Seq(df_MSK.loc[i,'search_hairpin_D']).reverse_complement()).lower(), 1, -2, -3, -1, score_only = True)\n",
    "    df_MSK.loc[i, 'possible_hairpin_E_1'] = pairwise2.align.localms(df_MSK.loc[i,'palindrome'], str(Seq(df_MSK.loc[i,'search_hairpin_E']).reverse_complement()).lower(), 1, -1, -1, -1, score_only = True)\n",
    "    df_MSK.loc[i, 'possible_hairpin_E_2'] = pairwise2.align.localms(df_MSK.loc[i,'palindrome'], str(Seq(df_MSK.loc[i,'search_hairpin_E']).reverse_complement()).lower(), 1, -1, -2, -1, score_only = True)\n",
    "    df_MSK.loc[i, 'possible_hairpin_E_3'] = pairwise2.align.localms(df_MSK.loc[i,'palindrome'], str(Seq(df_MSK.loc[i,'search_hairpin_E']).reverse_complement()).lower(), 1, -2, -1, -1, score_only = True)\n",
    "    df_MSK.loc[i, 'possible_hairpin_E_4'] = pairwise2.align.localms(df_MSK.loc[i,'palindrome'], str(Seq(df_MSK.loc[i,'search_hairpin_E']).reverse_complement()).lower(), 1, -2, -2, -1, score_only = True)\n",
    "    df_MSK.loc[i, 'possible_hairpin_E_5'] = pairwise2.align.localms(df_MSK.loc[i,'palindrome'], str(Seq(df_MSK.loc[i,'search_hairpin_E']).reverse_complement()).lower(), 1, -3, -2, -1, score_only = True)\n",
    "    df_MSK.loc[i, 'possible_hairpin_E_6'] = pairwise2.align.localms(df_MSK.loc[i,'palindrome'], str(Seq(df_MSK.loc[i,'search_hairpin_E']).reverse_complement()).lower(), 1, -2, -3, -1, score_only = True)\n",
    "    tmp_BLAT = result_BLAT[result_BLAT[9] == i]\n",
    "    tmp_BLAT = tmp_BLAT[tmp_BLAT[22].str.contains(df_MSK.loc[i, 'search_seq_A'].lower())]\n",
    "    tmp_BLAT = tmp_BLAT[tmp_BLAT[7] < 10]\n",
    "    if tmp_BLAT.shape[0] > 0:\n",
    "        for j in range(tmp_BLAT.shape[0]):\n",
    "            tmp_score = tmp_BLAT.iloc[j,12]\n",
    "            if tmp_score >= 20:\n",
    "                df_MSK.loc[i, 'score_A_20'] = df_MSK.loc[i, 'score_A_20'] + 1\n",
    "            if tmp_score >= 25:\n",
    "                df_MSK.loc[i, 'score_A_25'] = df_MSK.loc[i, 'score_A_25'] + 1\n",
    "            if tmp_score >= 30:\n",
    "                df_MSK.loc[i, 'score_A_30'] = df_MSK.loc[i, 'score_A_30'] + 1\n",
    "            if tmp_score >= 35:\n",
    "                df_MSK.loc[i, 'score_A_35'] = df_MSK.loc[i, 'score_A_35'] + 1\n",
    "            if tmp_score >= 40:\n",
    "                df_MSK.loc[i, 'score_A_40'] = df_MSK.loc[i, 'score_A_40'] + 1\n",
    "            if tmp_score >= 45:\n",
    "                df_MSK.loc[i, 'score_A_45'] = df_MSK.loc[i, 'score_A_45'] + 1\n",
    "            if tmp_score >= 50:\n",
    "                df_MSK.loc[i, 'score_A_50'] = df_MSK.loc[i, 'score_A_50'] + 1\n",
    "            if tmp_score >= 55:\n",
    "                df_MSK.loc[i, 'score_A_55'] = df_MSK.loc[i, 'score_A_55'] + 1\n",
    "            if tmp_score >= 60:\n",
    "                df_MSK.loc[i, 'score_A_60'] = df_MSK.loc[i, 'score_A_60'] + 1\n",
    "    tmp_BLAT = result_BLAT[result_BLAT[9] == i]\n",
    "    tmp_BLAT = tmp_BLAT[tmp_BLAT[22].str.contains(df_MSK.loc[i, 'search_seq_B'].lower())]\n",
    "    tmp_BLAT = tmp_BLAT[tmp_BLAT[7] < 10]\n",
    "    if tmp_BLAT.shape[0] > 0:\n",
    "        for j in range(tmp_BLAT.shape[0]):\n",
    "            tmp_score = tmp_BLAT.iloc[j,12]\n",
    "            if tmp_score >= 20:\n",
    "                df_MSK.loc[i, 'score_B_20'] = df_MSK.loc[i, 'score_B_20'] + 1\n",
    "            if tmp_score >= 25:\n",
    "                df_MSK.loc[i, 'score_B_25'] = df_MSK.loc[i, 'score_B_25'] + 1\n",
    "            if tmp_score >= 30:\n",
    "                df_MSK.loc[i, 'score_B_30'] = df_MSK.loc[i, 'score_B_30'] + 1\n",
    "            if tmp_score >= 35:\n",
    "                df_MSK.loc[i, 'score_B_35'] = df_MSK.loc[i, 'score_B_35'] + 1\n",
    "            if tmp_score >= 40:\n",
    "                df_MSK.loc[i, 'score_B_40'] = df_MSK.loc[i, 'score_B_40'] + 1\n",
    "            if tmp_score >= 45:\n",
    "                df_MSK.loc[i, 'score_B_45'] = df_MSK.loc[i, 'score_B_45'] + 1\n",
    "            if tmp_score >= 50:\n",
    "                df_MSK.loc[i, 'score_B_50'] = df_MSK.loc[i, 'score_B_50'] + 1\n",
    "            if tmp_score >= 55:\n",
    "                df_MSK.loc[i, 'score_B_55'] = df_MSK.loc[i, 'score_B_55'] + 1\n",
    "            if tmp_score >= 60:\n",
    "                df_MSK.loc[i, 'score_B_60'] = df_MSK.loc[i, 'score_B_60'] + 1\n",
    "\n",
    "    tmp_BLAT = result_BLAT[result_BLAT[9] == i]\n",
    "    tmp_BLAT = tmp_BLAT[tmp_BLAT[22].str.contains(df_MSK.loc[i, 'search_seq_C'].lower())]\n",
    "    tmp_BLAT = tmp_BLAT[tmp_BLAT[7] < 10]\n",
    "    if tmp_BLAT.shape[0] > 0:\n",
    "        for j in range(tmp_BLAT.shape[0]):\n",
    "            tmp_score = tmp_BLAT.iloc[j,12]\n",
    "            if tmp_score >= 20:\n",
    "                df_MSK.loc[i, 'score_C_20'] = df_MSK.loc[i, 'score_C_20'] + 1\n",
    "            if tmp_score >= 25:\n",
    "                df_MSK.loc[i, 'score_C_25'] = df_MSK.loc[i, 'score_C_25'] + 1\n",
    "            if tmp_score >= 30:\n",
    "                df_MSK.loc[i, 'score_C_30'] = df_MSK.loc[i, 'score_C_30'] + 1\n",
    "            if tmp_score >= 35:\n",
    "                df_MSK.loc[i, 'score_C_35'] = df_MSK.loc[i, 'score_C_35'] + 1\n",
    "            if tmp_score >= 40:\n",
    "                df_MSK.loc[i, 'score_C_40'] = df_MSK.loc[i, 'score_C_40'] + 1\n",
    "            if tmp_score >= 45:\n",
    "                df_MSK.loc[i, 'score_C_45'] = df_MSK.loc[i, 'score_C_45'] + 1\n",
    "            if tmp_score >= 50:\n",
    "                df_MSK.loc[i, 'score_C_50'] = df_MSK.loc[i, 'score_C_50'] + 1\n",
    "            if tmp_score >= 55:\n",
    "                df_MSK.loc[i, 'score_C_55'] = df_MSK.loc[i, 'score_C_55'] + 1\n",
    "            if tmp_score >= 60:\n",
    "                df_MSK.loc[i, 'score_C_60'] = df_MSK.loc[i, 'score_C_60'] + 1\n",
    "\n",
    "    tmp_BLAT = result_BLAT[result_BLAT[9] == i]\n",
    "    tmp_BLAT = tmp_BLAT[tmp_BLAT[22].str.contains(df_MSK.loc[i, 'search_seq_D'].lower())]\n",
    "    tmp_BLAT = tmp_BLAT[tmp_BLAT[7] < 10]\n",
    "    if tmp_BLAT.shape[0] > 0:\n",
    "        for j in range(tmp_BLAT.shape[0]):\n",
    "            tmp_score = tmp_BLAT.iloc[j,12]\n",
    "            if tmp_score >= 20:\n",
    "                df_MSK.loc[i, 'score_D_20'] = df_MSK.loc[i, 'score_D_20'] + 1\n",
    "            if tmp_score >= 25:\n",
    "                df_MSK.loc[i, 'score_D_25'] = df_MSK.loc[i, 'score_D_25'] + 1\n",
    "            if tmp_score >= 30:\n",
    "                df_MSK.loc[i, 'score_D_30'] = df_MSK.loc[i, 'score_D_30'] + 1\n",
    "            if tmp_score >= 35:\n",
    "                df_MSK.loc[i, 'score_D_35'] = df_MSK.loc[i, 'score_D_35'] + 1\n",
    "            if tmp_score >= 40:\n",
    "                df_MSK.loc[i, 'score_D_40'] = df_MSK.loc[i, 'score_D_40'] + 1\n",
    "            if tmp_score >= 45:\n",
    "                df_MSK.loc[i, 'score_D_45'] = df_MSK.loc[i, 'score_D_45'] + 1\n",
    "            if tmp_score >= 50:\n",
    "                df_MSK.loc[i, 'score_D_50'] = df_MSK.loc[i, 'score_D_50'] + 1\n",
    "            if tmp_score >= 55:\n",
    "                df_MSK.loc[i, 'score_D_55'] = df_MSK.loc[i, 'score_D_55'] + 1\n",
    "            if tmp_score >= 60:\n",
    "                df_MSK.loc[i, 'score_D_60'] = df_MSK.loc[i, 'score_D_60'] + 1\n",
    "\n",
    "print(str(i + 1) + \" / \" + str(df_MSK.shape[0]))\n",
    "\n",
    "df_MSK.to_excel('/mnt/HDD8TB/MicroSEC/source/MANOSEC_processed_MSK.xlsx')\n",
    "\n",
    "X_MSK = df_MSK.loc[:, (\"%Alt\", \"rev_comp_seq\",\n",
    "               \"possible_hairpin_A_1\", \"possible_hairpin_A_2\", \"possible_hairpin_A_3\", \"possible_hairpin_A_4\", \"possible_hairpin_A_5\", \"possible_hairpin_A_6\",\n",
    "               \"possible_hairpin_B_1\", \"possible_hairpin_B_2\", \"possible_hairpin_B_3\", \"possible_hairpin_B_4\", \"possible_hairpin_B_5\", \"possible_hairpin_B_6\",\n",
    "               \"possible_hairpin_C_1\", \"possible_hairpin_C_2\", \"possible_hairpin_C_3\", \"possible_hairpin_C_4\", \"possible_hairpin_C_5\", \"possible_hairpin_C_6\",\n",
    "               \"possible_hairpin_D_1\", \"possible_hairpin_D_2\", \"possible_hairpin_D_3\", \"possible_hairpin_D_4\", \"possible_hairpin_D_5\", \"possible_hairpin_D_6\",\n",
    "               \"possible_hairpin_E_1\", \"possible_hairpin_E_2\", \"possible_hairpin_E_3\", \"possible_hairpin_E_4\", \"possible_hairpin_E_5\", \"possible_hairpin_E_6\",\n",
    "               \"score_A_20\", \"score_A_25\", \"score_A_30\", \"score_A_35\", \"score_A_40\", \"score_A_45\", \"score_A_50\", \"score_A_55\", \"score_A_60\",\n",
    "               \"score_A_20\", \"score_B_25\", \"score_B_30\", \"score_B_35\", \"score_B_40\", \"score_B_45\", \"score_B_50\", \"score_B_55\", \"score_B_60\",\n",
    "               \"score_C_20\", \"score_C_25\", \"score_C_30\", \"score_C_35\", \"score_C_40\", \"score_C_45\", \"score_C_50\", \"score_C_55\", \"score_C_60\",\n",
    "               \"score_D_20\", \"score_D_25\", \"score_D_30\", \"score_D_35\", \"score_D_40\", \"score_D_45\", \"score_D_50\", \"score_D_55\", \"score_D_60\",\n",
    "              )]\n",
    "\n",
    "X_MSK[\"SNV\"] = df_MSK.loc[:, (\"Mut_type\")].str.contains(\"snv\").astype(int)\n",
    "X_MSK[\"DEL\"] = df_MSK.loc[:, (\"Mut_type\")].str.contains(\"del\").astype(int)\n",
    "X_MSK[\"INS\"] = df_MSK.loc[:, (\"Mut_type\")].str.contains(\"ins\").astype(int)\n",
    "X_MSK[\"bases\"] = df_MSK.loc[:, (\"Mut_type\")].str.split(\"-\", expand=True)[0].astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('/mnt/HDD8TB/MicroSEC/source/MANOSEC_processed.xlsx')\n",
    "\n",
    "X = df.loc[:, (\"%Alt\", \"rev_comp_seq\",\n",
    "               \"possible_hairpin_A_1\", \"possible_hairpin_A_2\", \"possible_hairpin_A_3\", \"possible_hairpin_A_4\", \"possible_hairpin_A_5\", \"possible_hairpin_A_6\",\n",
    "               \"possible_hairpin_B_1\", \"possible_hairpin_B_2\", \"possible_hairpin_B_3\", \"possible_hairpin_B_4\", \"possible_hairpin_B_5\", \"possible_hairpin_B_6\",\n",
    "               \"possible_hairpin_C_1\", \"possible_hairpin_C_2\", \"possible_hairpin_C_3\", \"possible_hairpin_C_4\", \"possible_hairpin_C_5\", \"possible_hairpin_C_6\",\n",
    "               \"possible_hairpin_D_1\", \"possible_hairpin_D_2\", \"possible_hairpin_D_3\", \"possible_hairpin_D_4\", \"possible_hairpin_D_5\", \"possible_hairpin_D_6\",\n",
    "               \"possible_hairpin_E_1\", \"possible_hairpin_E_2\", \"possible_hairpin_E_3\", \"possible_hairpin_E_4\", \"possible_hairpin_E_5\", \"possible_hairpin_E_6\",\n",
    "               \"score_A_20\", \"score_A_25\", \"score_A_30\", \"score_A_35\", \"score_A_40\", \"score_A_45\", \"score_A_50\", \"score_A_55\", \"score_A_60\",\n",
    "               \"score_B_20\", \"score_B_25\", \"score_B_30\", \"score_B_35\", \"score_B_40\", \"score_B_45\", \"score_B_50\", \"score_B_55\", \"score_B_60\",\n",
    "               \"score_C_20\", \"score_C_25\", \"score_C_30\", \"score_C_35\", \"score_C_40\", \"score_C_45\", \"score_C_50\", \"score_C_55\", \"score_C_60\",\n",
    "               \"score_D_20\", \"score_D_25\", \"score_D_30\", \"score_D_35\", \"score_D_40\", \"score_D_45\", \"score_D_50\", \"score_D_55\", \"score_D_60\",\n",
    "              )]\n",
    "X[\"SNV\"] = df.loc[:, (\"Mut_type\")].str.contains(\"snv\").astype(int)\n",
    "X[\"DEL\"] = df.loc[:, (\"Mut_type\")].str.contains(\"del\").astype(int)\n",
    "X[\"INS\"] = df.loc[:, (\"Mut_type\")].str.contains(\"ins\").astype(int)\n",
    "X[\"bases\"] = df.loc[:, (\"Mut_type\")].str.split(\"-\", expand=True)[0].astype(int)\n",
    "\n",
    "y = (df.loc[:, \"msec_filter_1234\"]).astype(int)\n",
    "\n",
    "\n",
    "df_MSK = pd.read_excel('/mnt/HDD8TB/MicroSEC/source/MANOSEC_processed_MSK.xlsx')\n",
    "\n",
    "X_MSK = df_MSK.loc[:, (\"%Alt\", \"rev_comp_seq\",\n",
    "               \"possible_hairpin_A_1\", \"possible_hairpin_A_2\", \"possible_hairpin_A_3\", \"possible_hairpin_A_4\", \"possible_hairpin_A_5\", \"possible_hairpin_A_6\",\n",
    "               \"possible_hairpin_B_1\", \"possible_hairpin_B_2\", \"possible_hairpin_B_3\", \"possible_hairpin_B_4\", \"possible_hairpin_B_5\", \"possible_hairpin_B_6\",\n",
    "               \"possible_hairpin_C_1\", \"possible_hairpin_C_2\", \"possible_hairpin_C_3\", \"possible_hairpin_C_4\", \"possible_hairpin_C_5\", \"possible_hairpin_C_6\",\n",
    "               \"possible_hairpin_D_1\", \"possible_hairpin_D_2\", \"possible_hairpin_D_3\", \"possible_hairpin_D_4\", \"possible_hairpin_D_5\", \"possible_hairpin_D_6\",\n",
    "               \"possible_hairpin_E_1\", \"possible_hairpin_E_2\", \"possible_hairpin_E_3\", \"possible_hairpin_E_4\", \"possible_hairpin_E_5\", \"possible_hairpin_E_6\",\n",
    "               \"score_A_20\", \"score_A_25\", \"score_A_30\", \"score_A_35\", \"score_A_40\", \"score_A_45\", \"score_A_50\", \"score_A_55\", \"score_A_60\",\n",
    "               \"score_B_20\", \"score_B_25\", \"score_B_30\", \"score_B_35\", \"score_B_40\", \"score_B_45\", \"score_B_50\", \"score_B_55\", \"score_B_60\",\n",
    "               \"score_C_20\", \"score_C_25\", \"score_C_30\", \"score_C_35\", \"score_C_40\", \"score_C_45\", \"score_C_50\", \"score_C_55\", \"score_C_60\",\n",
    "               \"score_D_20\", \"score_D_25\", \"score_D_30\", \"score_D_35\", \"score_D_40\", \"score_D_45\", \"score_D_50\", \"score_D_55\", \"score_D_60\",\n",
    "              )]\n",
    "\n",
    "X_MSK[\"SNV\"] = df_MSK.loc[:, (\"Mut_type\")].str.contains(\"snv\").astype(int)\n",
    "X_MSK[\"DEL\"] = df_MSK.loc[:, (\"Mut_type\")].str.contains(\"del\").astype(int)\n",
    "X_MSK[\"INS\"] = df_MSK.loc[:, (\"Mut_type\")].str.contains(\"ins\").astype(int)\n",
    "X_MSK[\"bases\"] = df_MSK.loc[:, (\"Mut_type\")].str.split(\"-\", expand=True)[0].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "# 5-fold cross validation\n",
    "# Training:Validation:Test = 3:1:1\n",
    "\n",
    "X_LR = np.array(X)\n",
    "y_LR = np.array(y)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "y_pred_total_LR = []\n",
    "y_proba_total_LR = []\n",
    "y_true_LR = []\n",
    "for train, test in skf.split(X_LR, y_LR):\n",
    "    X_train = X_LR[train]\n",
    "    X_test = X_LR[test]\n",
    "    y_train = y_LR[train]\n",
    "    y_test = y_LR[test]\n",
    "    #X_train, X_valid, y_train, y_valid = train_test_split(X_tv, y_tv, shuffle=True, test_size=0.25, stratify=y_tv, random_state=100)\n",
    "\n",
    "    search_params = [\n",
    "        {'solver': ['liblinear', 'saga'],\n",
    "         'penalty':['l1', 'l2'],\n",
    "         'C': [0.1, 1, 10, 100],\n",
    "         'random_state': [2525]},\n",
    "        {'solver': ['newton-cg', 'sag', 'lbfgs' ],\n",
    "         'penalty':['l2'],\n",
    "         'C': [0.1, 1, 10, 100],\n",
    "         'random_state': [2525]},\n",
    "    ]\n",
    "\n",
    "\n",
    "    clf = GridSearchCV(LogisticRegression(),\n",
    "                      search_params,\n",
    "                      cv=4,\n",
    "                      verbose=False,\n",
    "                      scoring='neg_log_loss',\n",
    "                      n_jobs=-1)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(clf.best_estimator_)\n",
    "    print(f\"acc: {clf.score(X_test, y_test)}\")\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_proba = clf.predict_proba(X_test)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_proba[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print (\"AUC curve : %f\" % roc_auc)\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC curve: AUC=%0.2f' % roc_auc)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    y_pred_total_LR = np.concatenate([y_pred_total_LR, y_pred])\n",
    "    y_proba_total_LR = np.concatenate([y_proba_total_LR, y_proba[:, 1]])\n",
    "    y_true_LR = np.concatenate([y_true_LR, y_test])\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true_LR, y_proba_total_LR)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print (\"AUC curve : %f\" % roc_auc)\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve: AUC=%0.2f' % roc_auc)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "y_pred_temp_25 = copy.deepcopy(y_proba_total_LR)\n",
    "for i in range(len(y_proba_total_LR)):\n",
    "    if y_proba_total_LR[i]>=0.25:\n",
    "        y_pred_temp_25[i]=1\n",
    "    else:\n",
    "        y_pred_temp_25[i]=0\n",
    "\n",
    "y_pred_temp_50 = copy.deepcopy(y_proba_total_LR)\n",
    "for i in range(len(y_proba_total_LR)):\n",
    "    if y_proba_total_LR[i]>=0.5:\n",
    "        y_pred_temp_50[i]=1\n",
    "    else:\n",
    "        y_pred_temp_50[i]=0\n",
    "\n",
    "y_pred_temp_75 = copy.deepcopy(y_proba_total_LR)\n",
    "for i in range(len(y_proba_total_LR)):\n",
    "    if y_proba_total_LR[i]>=0.75:\n",
    "        y_pred_temp_75[i]=1\n",
    "    else:\n",
    "        y_pred_temp_75[i]=0\n",
    "\n",
    "y_pred_temp_90 = copy.deepcopy(y_proba_total_LR)\n",
    "for i in range(len(y_proba_total_LR)):\n",
    "    if y_proba_total_LR[i]>=0.9:\n",
    "        y_pred_temp_90[i]=1\n",
    "    else:\n",
    "        y_pred_temp_90[i]=0\n",
    "\n",
    "y_pred_temp_95 = copy.deepcopy(y_proba_total_LR)\n",
    "for i in range(len(y_proba_total_LR)):\n",
    "    if y_proba_total_LR[i]>=0.95:\n",
    "        y_pred_temp_95[i]=1\n",
    "    else:\n",
    "        y_pred_temp_95[i]=0\n",
    "\n",
    "y_pred_temp_975 = copy.deepcopy(y_proba_total_LR)\n",
    "for i in range(len(y_proba_total_LR)):\n",
    "    if y_proba_total_LR[i]>=0.975:\n",
    "        y_pred_temp_975[i]=1\n",
    "    else:\n",
    "        y_pred_temp_975[i]=0\n",
    "\n",
    "y_pred_temp_99 = copy.deepcopy(y_proba_total_LR)\n",
    "for i in range(len(y_proba_total_LR)):\n",
    "    if y_proba_total_LR[i]>=0.99:\n",
    "        y_pred_temp_99[i]=1\n",
    "    else:\n",
    "        y_pred_temp_99[i]=0\n",
    "\n",
    "conf_matrix_LR = confusion_matrix(y_pred_temp_25, y_true_LR)\n",
    "conf_matrix_LR = np.concatenate([conf_matrix_LR, confusion_matrix(y_pred_temp_50, y_true_LR)])\n",
    "conf_matrix_LR = np.concatenate([conf_matrix_LR, confusion_matrix(y_pred_temp_75, y_true_LR)])\n",
    "conf_matrix_LR = np.concatenate([conf_matrix_LR, confusion_matrix(y_pred_temp_90, y_true_LR)])\n",
    "conf_matrix_LR = np.concatenate([conf_matrix_LR, confusion_matrix(y_pred_temp_95, y_true_LR)])\n",
    "conf_matrix_LR = np.concatenate([conf_matrix_LR, confusion_matrix(y_pred_temp_975, y_true_LR)])\n",
    "conf_matrix_LR = np.concatenate([conf_matrix_LR, confusion_matrix(y_pred_temp_99, y_true_LR)])\n",
    "\n",
    "conf_table_LR = pd.DataFrame(conf_matrix_LR, index=['LR_predicted_25 mutation', 'LR_predicted_25 artifact', \n",
    "                                              'LR_predicted_50 mutation', 'LR_predicted_50 artifact',\n",
    "                                              'LR_predicted_75 mutation', 'LR_predicted_75 artifact',\n",
    "                                              'LR_predicted_90 mutation', 'LR_predicted_90 artifact',\n",
    "                                              'LR_predicted_95 mutation', 'LR_predicted_95 artifact',\n",
    "                                              'LR_predicted_97.5 mutation', 'LR_predicted_97.5 artifact',\n",
    "                                              'LR_predicted_99 mutation', 'LR_predicted_99 artifact'],\n",
    "                                       columns=['MicroSEC mutation', 'MicroSEC artifact'])\n",
    "\n",
    "conf_table_LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest classifier\n",
    "# 5-fold cross validation\n",
    "# Training:Validation:Test = 3:1:1\n",
    "\n",
    "X_RF = np.array(X)\n",
    "y_RF = np.array(y)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "y_pred_total = []\n",
    "y_proba_total = []\n",
    "y_true = []\n",
    "for train, test in skf.split(X_RF, y_RF):\n",
    "    X_train = X_RF[train]\n",
    "    X_test = X_RF[test]\n",
    "    y_train = y_RF[train]\n",
    "    y_test = y_RF[test]\n",
    "    #X_train, X_valid, y_train, y_valid = train_test_split(X_tv, y_tv, shuffle=True, test_size=0.25, stratify=y_tv, random_state=100)\n",
    "\n",
    "    search_params = {\n",
    "        'n_estimators'      : [10, 15, 20, 30],\n",
    "        'max_features'      : [6, 8, 10, 14, 18],\n",
    "        'random_state'      : [2525],\n",
    "        'min_samples_split' : [2, 3, 5, 10],\n",
    "        'max_depth'         : [20, 25, 30]\n",
    "    }\n",
    "\n",
    "\n",
    "    gs = GridSearchCV(RFC(),\n",
    "                      search_params,\n",
    "                      cv=4,\n",
    "                      verbose=False,\n",
    "                      scoring='neg_log_loss',\n",
    "                      n_jobs=-1)\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    print(gs.best_estimator_)\n",
    "    print(f\"acc: {gs.score(X_test, y_test)}\")\n",
    "    y_pred = gs.predict(X_test)\n",
    "    y_proba = gs.predict_proba(X_test)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_proba[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print (\"AUC curve : %f\" % roc_auc)\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC curve: AUC=%0.2f' % roc_auc)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    y_pred_total = np.concatenate([y_pred_total, y_pred])\n",
    "    y_proba_total = np.concatenate([y_proba_total, y_proba[:, 1]])\n",
    "    y_true = np.concatenate([y_true, y_test])\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_proba_total)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print (\"AUC curve : %f\" % roc_auc)\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve: AUC=%0.2f' % roc_auc)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "y_pred_temp_25 = copy.deepcopy(y_proba_total)\n",
    "for i in range(len(y_proba_total)):\n",
    "    if y_proba_total[i]>=0.25:\n",
    "        y_pred_temp_25[i]=1\n",
    "    else:\n",
    "        y_pred_temp_25[i]=0\n",
    "\n",
    "y_pred_temp_50 = copy.deepcopy(y_proba_total)\n",
    "for i in range(len(y_proba_total)):\n",
    "    if y_proba_total[i]>=0.5:\n",
    "        y_pred_temp_50[i]=1\n",
    "    else:\n",
    "        y_pred_temp_50[i]=0\n",
    "\n",
    "y_pred_temp_75 = copy.deepcopy(y_proba_total)\n",
    "for i in range(len(y_proba_total)):\n",
    "    if y_proba_total[i]>=0.75:\n",
    "        y_pred_temp_75[i]=1\n",
    "    else:\n",
    "        y_pred_temp_75[i]=0\n",
    "\n",
    "y_pred_temp_90 = copy.deepcopy(y_proba_total)\n",
    "for i in range(len(y_proba_total)):\n",
    "    if y_proba_total[i]>=0.9:\n",
    "        y_pred_temp_90[i]=1\n",
    "    else:\n",
    "        y_pred_temp_90[i]=0\n",
    "\n",
    "y_pred_temp_95 = copy.deepcopy(y_proba_total)\n",
    "for i in range(len(y_proba_total)):\n",
    "    if y_proba_total[i]>=0.95:\n",
    "        y_pred_temp_95[i]=1\n",
    "    else:\n",
    "        y_pred_temp_95[i]=0\n",
    "\n",
    "y_pred_temp_975 = copy.deepcopy(y_proba_total)\n",
    "for i in range(len(y_proba_total)):\n",
    "    if y_proba_total[i]>=0.975:\n",
    "        y_pred_temp_975[i]=1\n",
    "    else:\n",
    "        y_pred_temp_975[i]=0\n",
    "\n",
    "y_pred_temp_99 = copy.deepcopy(y_proba_total)\n",
    "for i in range(len(y_proba_total)):\n",
    "    if y_proba_total[i]>=0.99:\n",
    "        y_pred_temp_99[i]=1\n",
    "    else:\n",
    "        y_pred_temp_99[i]=0\n",
    "\n",
    "conf_matrix = confusion_matrix(y_pred_temp_25, y_true)\n",
    "conf_matrix = np.concatenate([conf_matrix, confusion_matrix(y_pred_temp_50, y_true)])\n",
    "conf_matrix = np.concatenate([conf_matrix, confusion_matrix(y_pred_temp_75, y_true)])\n",
    "conf_matrix = np.concatenate([conf_matrix, confusion_matrix(y_pred_temp_90, y_true)])\n",
    "conf_matrix = np.concatenate([conf_matrix, confusion_matrix(y_pred_temp_95, y_true)])\n",
    "conf_matrix = np.concatenate([conf_matrix, confusion_matrix(y_pred_temp_975, y_true)])\n",
    "conf_matrix = np.concatenate([conf_matrix, confusion_matrix(y_pred_temp_99, y_true)])\n",
    "\n",
    "conf_table = pd.DataFrame(conf_matrix, index=['RF_predicted_25 mutation', 'RF_predicted_25 artifact', \n",
    "                                              'RF_predicted_50 mutation', 'RF_predicted_50 artifact',\n",
    "                                              'RF_predicted_75 mutation', 'RF_predicted_75 artifact',\n",
    "                                              'RF_predicted_90 mutation', 'RF_predicted_90 artifact',\n",
    "                                              'RF_predicted_95 mutation', 'RF_predicted_95 artifact',\n",
    "                                              'RF_predicted_97.5 mutation', 'RF_predicted_97.5 artifact',\n",
    "                                              'RF_predicted_99 mutation', 'RF_predicted_99 artifact'],\n",
    "                                       columns=['MicroSEC mutation', 'MicroSEC artifact'])\n",
    "\n",
    "conf_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree cllasifier and ADABoost\n",
    "# 5-fold cross validation\n",
    "# Training:Validation:Test = 3:1:1\n",
    "\n",
    "X_DT = np.array(X)\n",
    "y_DT = np.array(y)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "y_pred_total_DT = []\n",
    "y_proba_total_DT = []\n",
    "y_true_DT = []\n",
    "\n",
    "y_pred_total_ADA = []\n",
    "y_proba_total_ADA = []\n",
    "y_true_ADA = []\n",
    "\n",
    "for train, test in skf.split(X_DT, y_DT):\n",
    "    X_train = X_DT[train]\n",
    "    X_test = X_DT[test]\n",
    "    y_train = y_DT[train]\n",
    "    y_test = y_DT[test]\n",
    "    #X_train, X_valid, y_train, y_valid = train_test_split(X_tv, y_tv, shuffle=True, test_size=0.25, stratify=y_tv, random_state=100)\n",
    "\n",
    "    search_params = {\"criterion\": [\"gini\", \"entropy\"],\n",
    "                     \"splitter\": [\"best\", \"random\"],\n",
    "                     \"max_depth\": [i for i in range(5, 11)],\n",
    "                     \"min_samples_split\": [i for i in range(2, 11)],\n",
    "                     \"min_samples_leaf\": [i for i in range(2, 11)],\n",
    "                     \"random_state\": [2525]\n",
    "                    }\n",
    "\n",
    "    dt = GridSearchCV(DecisionTreeClassifier(),\n",
    "                      search_params,\n",
    "                      cv=4,\n",
    "                      verbose=False,\n",
    "                      n_jobs=-1)\n",
    "    dt.fit(X_train, y_train)\n",
    "    criterion_dt, max_depth_dt, min_samples_leaf_dt, min_samples_split_dt, random_state_dt, splitter_dt = dt.best_params_.values()\n",
    "    ada = AdaBoostClassifier(DecisionTreeClassifier(criterion=criterion_dt, max_depth=max_depth_dt, min_samples_leaf=min_samples_leaf_dt, random_state=random_state_dt, splitter=splitter_dt))\n",
    "    ada.fit(X_train, y_train)\n",
    "\n",
    "    print(dt.best_estimator_)\n",
    "    print(f\"acc: {dt.score(X_test, y_test)}\")\n",
    "    print(f\"acc: {ada.score(X_test, y_test)}\")\n",
    "\n",
    "    y_pred = dt.predict(X_test)\n",
    "    y_proba = dt.predict_proba(X_test)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_proba[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print (\"AUC curve : %f\" % roc_auc)\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC curve: AUC=%0.2f' % roc_auc)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    y_pred_total_DT = np.concatenate([y_pred_total_DT, y_pred])\n",
    "    y_proba_total_DT = np.concatenate([y_proba_total_DT, y_proba[:, 1]])\n",
    "    y_true_DT = np.concatenate([y_true_DT, y_test])\n",
    "\n",
    "    y_pred = ada.predict(X_test)\n",
    "    y_proba = ada.predict_proba(X_test)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_proba[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print (\"AUC curve : %f\" % roc_auc)\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC curve: AUC=%0.2f' % roc_auc)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    y_pred_total_ADA = np.concatenate([y_pred_total_ADA, y_pred])\n",
    "    y_proba_total_ADA = np.concatenate([y_proba_total_ADA, y_proba[:, 1]])\n",
    "    y_true_ADA = np.concatenate([y_true_ADA, y_test])\n",
    "\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true_DT, y_proba_total_DT)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print (\"AUC curve : %f\" % roc_auc)\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve: AUC=%0.2f' % roc_auc)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true_ADA, y_proba_total_ADA)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print (\"AUC curve : %f\" % roc_auc)\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve: AUC=%0.2f' % roc_auc)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "y_pred_temp_25 = copy.deepcopy(y_proba_total_DT)\n",
    "for i in range(len(y_proba_total_DT)):\n",
    "    if y_proba_total_DT[i]>=0.25:\n",
    "        y_pred_temp_25[i]=1\n",
    "    else:\n",
    "        y_pred_temp_25[i]=0\n",
    "\n",
    "y_pred_temp_50 = copy.deepcopy(y_proba_total_DT)\n",
    "for i in range(len(y_proba_total_DT)):\n",
    "    if y_proba_total_DT[i]>=0.5:\n",
    "        y_pred_temp_50[i]=1\n",
    "    else:\n",
    "        y_pred_temp_50[i]=0\n",
    "\n",
    "y_pred_temp_75 = copy.deepcopy(y_proba_total_DT)\n",
    "for i in range(len(y_proba_total_DT)):\n",
    "    if y_proba_total_DT[i]>=0.75:\n",
    "        y_pred_temp_75[i]=1\n",
    "    else:\n",
    "        y_pred_temp_75[i]=0\n",
    "\n",
    "y_pred_temp_90 = copy.deepcopy(y_proba_total_DT)\n",
    "for i in range(len(y_proba_total_DT)):\n",
    "    if y_proba_total_DT[i]>=0.9:\n",
    "        y_pred_temp_90[i]=1\n",
    "    else:\n",
    "        y_pred_temp_90[i]=0\n",
    "\n",
    "y_pred_temp_95 = copy.deepcopy(y_proba_total_DT)\n",
    "for i in range(len(y_proba_total_DT)):\n",
    "    if y_proba_total_DT[i]>=0.95:\n",
    "        y_pred_temp_95[i]=1\n",
    "    else:\n",
    "        y_pred_temp_95[i]=0\n",
    "\n",
    "y_pred_temp_975 = copy.deepcopy(y_proba_total_DT)\n",
    "for i in range(len(y_proba_total_DT)):\n",
    "    if y_proba_total_DT[i]>=0.975:\n",
    "        y_pred_temp_975[i]=1\n",
    "    else:\n",
    "        y_pred_temp_975[i]=0\n",
    "\n",
    "y_pred_temp_99 = copy.deepcopy(y_proba_total_DT)\n",
    "for i in range(len(y_proba_total_DT)):\n",
    "    if y_proba_total_DT[i]>=0.99:\n",
    "        y_pred_temp_99[i]=1\n",
    "    else:\n",
    "        y_pred_temp_99[i]=0\n",
    "\n",
    "conf_matrix_DT = confusion_matrix(y_pred_temp_25, y_true_DT)\n",
    "conf_matrix_DT = np.concatenate([conf_matrix_DT, confusion_matrix(y_pred_temp_50, y_true_DT)])\n",
    "conf_matrix_DT = np.concatenate([conf_matrix_DT, confusion_matrix(y_pred_temp_75, y_true_DT)])\n",
    "conf_matrix_DT = np.concatenate([conf_matrix_DT, confusion_matrix(y_pred_temp_90, y_true_DT)])\n",
    "conf_matrix_DT = np.concatenate([conf_matrix_DT, confusion_matrix(y_pred_temp_95, y_true_DT)])\n",
    "conf_matrix_DT = np.concatenate([conf_matrix_DT, confusion_matrix(y_pred_temp_975, y_true_DT)])\n",
    "conf_matrix_DT = np.concatenate([conf_matrix_DT, confusion_matrix(y_pred_temp_99, y_true_DT)])\n",
    "\n",
    "conf_table_DT = pd.DataFrame(conf_matrix_DT, index=['DT_predicted_25 mutation', 'DT_predicted_25 artifact', \n",
    "                                              'DT_predicted_50 mutation', 'DT_predicted_50 artifact',\n",
    "                                              'DT_predicted_75 mutation', 'DT_predicted_75 artifact',\n",
    "                                              'DT_predicted_90 mutation', 'DT_predicted_90 artifact',\n",
    "                                              'DT_predicted_95 mutation', 'DT_predicted_95 artifact',\n",
    "                                              'DT_predicted_97.5 mutation', 'DT_predicted_97.5 artifact',\n",
    "                                              'DT_predicted_99 mutation', 'DT_predicted_99 artifact'],\n",
    "                                       columns=['MicroSEC mutation', 'MicroSEC artifact'])\n",
    "\n",
    "y_pred_temp_25 = copy.deepcopy(y_proba_total_ADA)\n",
    "for i in range(len(y_proba_total_ADA)):\n",
    "    if y_proba_total_ADA[i]>=0.25:\n",
    "        y_pred_temp_25[i]=1\n",
    "    else:\n",
    "        y_pred_temp_25[i]=0\n",
    "\n",
    "y_pred_temp_50 = copy.deepcopy(y_proba_total_ADA)\n",
    "for i in range(len(y_proba_total_ADA)):\n",
    "    if y_proba_total_ADA[i]>=0.5:\n",
    "        y_pred_temp_50[i]=1\n",
    "    else:\n",
    "        y_pred_temp_50[i]=0\n",
    "\n",
    "y_pred_temp_75 = copy.deepcopy(y_proba_total_ADA)\n",
    "for i in range(len(y_proba_total_ADA)):\n",
    "    if y_proba_total_ADA[i]>=0.75:\n",
    "        y_pred_temp_75[i]=1\n",
    "    else:\n",
    "        y_pred_temp_75[i]=0\n",
    "\n",
    "y_pred_temp_90 = copy.deepcopy(y_proba_total_ADA)\n",
    "for i in range(len(y_proba_total_ADA)):\n",
    "    if y_proba_total_ADA[i]>=0.9:\n",
    "        y_pred_temp_90[i]=1\n",
    "    else:\n",
    "        y_pred_temp_90[i]=0\n",
    "\n",
    "y_pred_temp_95 = copy.deepcopy(y_proba_total_ADA)\n",
    "for i in range(len(y_proba_total_ADA)):\n",
    "    if y_proba_total_ADA[i]>=0.95:\n",
    "        y_pred_temp_95[i]=1\n",
    "    else:\n",
    "        y_pred_temp_95[i]=0\n",
    "\n",
    "y_pred_temp_975 = copy.deepcopy(y_proba_total_ADA)\n",
    "for i in range(len(y_proba_total_ADA)):\n",
    "    if y_proba_total_ADA[i]>=0.975:\n",
    "        y_pred_temp_975[i]=1\n",
    "    else:\n",
    "        y_pred_temp_975[i]=0\n",
    "\n",
    "y_pred_temp_99 = copy.deepcopy(y_proba_total_ADA)\n",
    "for i in range(len(y_proba_total_ADA)):\n",
    "    if y_proba_total_ADA[i]>=0.99:\n",
    "        y_pred_temp_99[i]=1\n",
    "    else:\n",
    "        y_pred_temp_99[i]=0\n",
    "\n",
    "conf_matrix_ADA = confusion_matrix(y_pred_temp_25, y_true_ADA)\n",
    "conf_matrix_ADA = np.concatenate([conf_matrix_ADA, confusion_matrix(y_pred_temp_50, y_true_ADA)])\n",
    "conf_matrix_ADA = np.concatenate([conf_matrix_ADA, confusion_matrix(y_pred_temp_75, y_true_ADA)])\n",
    "conf_matrix_ADA = np.concatenate([conf_matrix_ADA, confusion_matrix(y_pred_temp_90, y_true_ADA)])\n",
    "conf_matrix_ADA = np.concatenate([conf_matrix_ADA, confusion_matrix(y_pred_temp_95, y_true_ADA)])\n",
    "conf_matrix_ADA = np.concatenate([conf_matrix_ADA, confusion_matrix(y_pred_temp_975, y_true_ADA)])\n",
    "conf_matrix_ADA = np.concatenate([conf_matrix_ADA, confusion_matrix(y_pred_temp_99, y_true_ADA)])\n",
    "\n",
    "conf_table_ADA = pd.DataFrame(conf_matrix_ADA, index=['ADA_predicted_25 mutation', 'ADA_predicted_25 artifact', \n",
    "                                              'ADA_predicted_50 mutation', 'ADA_predicted_50 artifact',\n",
    "                                              'ADA_predicted_75 mutation', 'ADA_predicted_75 artifact',\n",
    "                                              'ADA_predicted_90 mutation', 'ADA_predicted_90 artifact',\n",
    "                                              'ADA_predicted_95 mutation', 'ADA_predicted_95 artifact',\n",
    "                                              'ADA_predicted_97.5 mutation', 'ADA_predicted_97.5 artifact',\n",
    "                                              'ADA_predicted_99 mutation', 'ADA_predicted_99 artifact'],\n",
    "                                       columns=['MicroSEC mutation', 'MicroSEC artifact'])\n",
    "pd.concat([conf_table_DT, conf_table_ADA], axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "# 5-fold cross validation\n",
    "# Training:Validation:Test = 3:1:1\n",
    "\n",
    "X_GNB = np.array(X)\n",
    "y_GNB = np.array(y)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "y_pred_total_GNB = []\n",
    "y_proba_total_GNB = []\n",
    "y_true_GNB = []\n",
    "for train, test in skf.split(X_GNB, y_GNB):\n",
    "    X_train = X_GNB[train]\n",
    "    X_test = X_GNB[test]\n",
    "    y_train = y_GNB[train]\n",
    "    y_test = y_GNB[test]\n",
    "    #X_train, X_valid, y_train, y_valid = train_test_split(X_tv, y_tv, shuffle=True, test_size=0.25, stratify=y_tv, random_state=100)\n",
    "\n",
    "    search_params = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "    GNB = GridSearchCV(GaussianNB(),\n",
    "                      search_params,\n",
    "                      cv=4,\n",
    "                      verbose=True,\n",
    "                      scoring='neg_log_loss',\n",
    "                      n_jobs=-1)\n",
    "    GNB.fit(X_train, y_train)\n",
    "\n",
    "    print(GNB.best_estimator_)\n",
    "    print(f\"acc: {GNB.score(X_test, y_test)}\")\n",
    "    y_pred = GNB.predict(X_test)\n",
    "    y_proba = GNB.predict_proba(X_test)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_proba[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print (\"AUC curve : %f\" % roc_auc)\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC curve: AUC=%0.2f' % roc_auc)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    y_pred_total_GNB = np.concatenate([y_pred_total_GNB, y_pred])\n",
    "    y_proba_total_GNB = np.concatenate([y_proba_total_GNB, y_proba[:, 1]])\n",
    "    y_true_GNB = np.concatenate([y_true_GNB, y_test])\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true_GNB, y_proba_total_GNB)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print (\"AUC curve : %f\" % roc_auc)\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve: AUC=%0.2f' % roc_auc)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "y_pred_temp_25 = copy.deepcopy(y_proba_total_GNB)\n",
    "for i in range(len(y_proba_total_GNB)):\n",
    "    if y_proba_total_GNB[i]>=0.25:\n",
    "        y_pred_temp_25[i]=1\n",
    "    else:\n",
    "        y_pred_temp_25[i]=0\n",
    "\n",
    "y_pred_temp_50 = copy.deepcopy(y_proba_total_GNB)\n",
    "for i in range(len(y_proba_total_GNB)):\n",
    "    if y_proba_total_GNB[i]>=0.5:\n",
    "        y_pred_temp_50[i]=1\n",
    "    else:\n",
    "        y_pred_temp_50[i]=0\n",
    "\n",
    "y_pred_temp_75 = copy.deepcopy(y_proba_total_GNB)\n",
    "for i in range(len(y_proba_total_GNB)):\n",
    "    if y_proba_total_GNB[i]>=0.75:\n",
    "        y_pred_temp_75[i]=1\n",
    "    else:\n",
    "        y_pred_temp_75[i]=0\n",
    "\n",
    "y_pred_temp_90 = copy.deepcopy(y_proba_total_GNB)\n",
    "for i in range(len(y_proba_total_GNB)):\n",
    "    if y_proba_total_GNB[i]>=0.9:\n",
    "        y_pred_temp_90[i]=1\n",
    "    else:\n",
    "        y_pred_temp_90[i]=0\n",
    "\n",
    "y_pred_temp_95 = copy.deepcopy(y_proba_total_GNB)\n",
    "for i in range(len(y_proba_total_GNB)):\n",
    "    if y_proba_total_GNB[i]>=0.95:\n",
    "        y_pred_temp_95[i]=1\n",
    "    else:\n",
    "        y_pred_temp_95[i]=0\n",
    "\n",
    "y_pred_temp_975 = copy.deepcopy(y_proba_total_GNB)\n",
    "for i in range(len(y_proba_total_GNB)):\n",
    "    if y_proba_total_GNB[i]>=0.975:\n",
    "        y_pred_temp_975[i]=1\n",
    "    else:\n",
    "        y_pred_temp_975[i]=0\n",
    "\n",
    "y_pred_temp_99 = copy.deepcopy(y_proba_total_GNB)\n",
    "for i in range(len(y_proba_total_GNB)):\n",
    "    if y_proba_total_GNB[i]>=0.99:\n",
    "        y_pred_temp_99[i]=1\n",
    "    else:\n",
    "        y_pred_temp_99[i]=0\n",
    "\n",
    "conf_matrix_GNB = confusion_matrix(y_pred_temp_25, y_true_GNB)\n",
    "conf_matrix_GNB = np.concatenate([conf_matrix_GNB, confusion_matrix(y_pred_temp_50, y_true_GNB)])\n",
    "conf_matrix_GNB = np.concatenate([conf_matrix_GNB, confusion_matrix(y_pred_temp_75, y_true_GNB)])\n",
    "conf_matrix_GNB = np.concatenate([conf_matrix_GNB, confusion_matrix(y_pred_temp_90, y_true_GNB)])\n",
    "conf_matrix_GNB = np.concatenate([conf_matrix_GNB, confusion_matrix(y_pred_temp_95, y_true_GNB)])\n",
    "conf_matrix_GNB = np.concatenate([conf_matrix_GNB, confusion_matrix(y_pred_temp_975, y_true_GNB)])\n",
    "conf_matrix_GNB = np.concatenate([conf_matrix_GNB, confusion_matrix(y_pred_temp_99, y_true_GNB)])\n",
    "\n",
    "conf_table_GNB = pd.DataFrame(conf_matrix_GNB, index=['GNB_predicted_25 mutation', 'GNB_predicted_25 artifact', \n",
    "                                              'GNB_predicted_50 mutation', 'GNB_predicted_50 artifact',\n",
    "                                              'GNB_predicted_75 mutation', 'GNB_predicted_75 artifact',\n",
    "                                              'GNB_predicted_90 mutation', 'GNB_predicted_90 artifact',\n",
    "                                              'GNB_predicted_95 mutation', 'GNB_predicted_95 artifact',\n",
    "                                              'GNB_predicted_97.5 mutation', 'GNB_predicted_97.5 artifact',\n",
    "                                              'GNB_predicted_99 mutation', 'GNB_predicted_99 artifact'],\n",
    "                                       columns=['MicroSEC mutation', 'MicroSEC artifact'])\n",
    "\n",
    "conf_table_GNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSK impact re-analysis with Random forest clasi\n",
    "\n",
    "gs = GridSearchCV(RFC(),\n",
    "                  search_params,\n",
    "                  cv=4,\n",
    "                  verbose=False,\n",
    "                  n_jobs=-1)\n",
    "gs.fit(X_RF, y_RF)\n",
    "\n",
    "print(gs.best_estimator_)\n",
    "\n",
    "y_MSK_proba = gs.predict_proba(X_MSK)[:,1]\n",
    "df_MSK[y_MSK_proba>0.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Light GBM\n",
    "# 5-fold cross validation\n",
    "# Training:Validation:Test = 3:1:1\n",
    "\n",
    "X_LGB = np.array(X)\n",
    "y_LGB = np.array(y)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "y_pred_total_LGB = []\n",
    "y_proba_total_LGB = []\n",
    "y_true_LGB = []\n",
    "for train, test in skf.split(X_LGB, y_LGB):\n",
    "    X_train = X_LGB[train]\n",
    "    X_test = X_LGB[test]\n",
    "    y_train = y_LGB[train]\n",
    "    y_test = y_LGB[test]\n",
    "\n",
    "    lgbm = lgb.LGBMClassifier(objective='binary')\n",
    "    \n",
    "    search_params = {'learning_rate':[0.01],\n",
    "                     'metric':['binary_logloss'],\n",
    "                     'num_iteration':[4000],\n",
    "                     'num_leaves':[3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                     'reg_alpha':[0, 1, 2, 3, 4, 5, 10, 100],\n",
    "                     'reg_lambda':[10, 15, 18, 20, 21, 22, 23, 25, 27, 29]\n",
    "                    }\n",
    "\n",
    "    LGB = GridSearchCV(lgbm,\n",
    "                      search_params,\n",
    "                      cv=4,\n",
    "                      verbose=True,\n",
    "                      scoring='neg_log_loss',\n",
    "                      n_jobs=-1)\n",
    "    LGB.fit(X_train, y_train)\n",
    "\n",
    "    print(LGB.best_estimator_)\n",
    "    print(f\"acc: {LGB.score(X_test, y_test)}\")\n",
    "    y_pred = LGB.predict(X_test)\n",
    "    y_proba = LGB.predict_proba(X_test)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_proba[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print (\"AUC curve : %f\" % roc_auc)\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC curve: AUC=%0.2f' % roc_auc)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    y_pred_total_LGB = np.concatenate([y_pred_total_LGB, y_pred])\n",
    "    y_proba_total_LGB = np.concatenate([y_proba_total_LGB, y_proba[:, 1]])\n",
    "    y_true_LGB = np.concatenate([y_true_LGB, y_test])\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true_LGB, y_proba_total_LGB)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print (\"AUC curve : %f\" % roc_auc)\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve: AUC=%0.2f' % roc_auc)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "y_pred_temp_25 = copy.deepcopy(y_proba_total_LGB)\n",
    "for i in range(len(y_proba_total_LGB)):\n",
    "    if y_proba_total_LGB[i]>=0.25:\n",
    "        y_pred_temp_25[i]=1\n",
    "    else:\n",
    "        y_pred_temp_25[i]=0\n",
    "\n",
    "y_pred_temp_50 = copy.deepcopy(y_proba_total_LGB)\n",
    "for i in range(len(y_proba_total_LGB)):\n",
    "    if y_proba_total_LGB[i]>=0.5:\n",
    "        y_pred_temp_50[i]=1\n",
    "    else:\n",
    "        y_pred_temp_50[i]=0\n",
    "\n",
    "y_pred_temp_75 = copy.deepcopy(y_proba_total_LGB)\n",
    "for i in range(len(y_proba_total_LGB)):\n",
    "    if y_proba_total_LGB[i]>=0.75:\n",
    "        y_pred_temp_75[i]=1\n",
    "    else:\n",
    "        y_pred_temp_75[i]=0\n",
    "\n",
    "y_pred_temp_90 = copy.deepcopy(y_proba_total_LGB)\n",
    "for i in range(len(y_proba_total_LGB)):\n",
    "    if y_proba_total_LGB[i]>=0.9:\n",
    "        y_pred_temp_90[i]=1\n",
    "    else:\n",
    "        y_pred_temp_90[i]=0\n",
    "\n",
    "y_pred_temp_95 = copy.deepcopy(y_proba_total_LGB)\n",
    "for i in range(len(y_proba_total_LGB)):\n",
    "    if y_proba_total_LGB[i]>=0.95:\n",
    "        y_pred_temp_95[i]=1\n",
    "    else:\n",
    "        y_pred_temp_95[i]=0\n",
    "\n",
    "y_pred_temp_975 = copy.deepcopy(y_proba_total_LGB)\n",
    "for i in range(len(y_proba_total_LGB)):\n",
    "    if y_proba_total_LGB[i]>=0.975:\n",
    "        y_pred_temp_975[i]=1\n",
    "    else:\n",
    "        y_pred_temp_975[i]=0\n",
    "\n",
    "y_pred_temp_99 = copy.deepcopy(y_proba_total_LGB)\n",
    "for i in range(len(y_proba_total_LGB)):\n",
    "    if y_proba_total_LGB[i]>=0.99:\n",
    "        y_pred_temp_99[i]=1\n",
    "    else:\n",
    "        y_pred_temp_99[i]=0\n",
    "\n",
    "conf_matrix_LGB = confusion_matrix(y_pred_temp_25, y_true_LGB)\n",
    "conf_matrix_LGB = np.concatenate([conf_matrix_LGB, confusion_matrix(y_pred_temp_50, y_true_LGB)])\n",
    "conf_matrix_LGB = np.concatenate([conf_matrix_LGB, confusion_matrix(y_pred_temp_75, y_true_LGB)])\n",
    "conf_matrix_LGB = np.concatenate([conf_matrix_LGB, confusion_matrix(y_pred_temp_90, y_true_LGB)])\n",
    "conf_matrix_LGB = np.concatenate([conf_matrix_LGB, confusion_matrix(y_pred_temp_95, y_true_LGB)])\n",
    "conf_matrix_LGB = np.concatenate([conf_matrix_LGB, confusion_matrix(y_pred_temp_975, y_true_LGB)])\n",
    "conf_matrix_LGB = np.concatenate([conf_matrix_LGB, confusion_matrix(y_pred_temp_99, y_true_LGB)])\n",
    "\n",
    "conf_table_LGB = pd.DataFrame(conf_matrix_LGB, index=['LGB_predicted_25 mutation', 'LGB_predicted_25 artifact', \n",
    "                                              'LGB_predicted_50 mutation', 'LGB_predicted_50 artifact',\n",
    "                                              'LGB_predicted_75 mutation', 'LGB_predicted_75 artifact',\n",
    "                                              'LGB_predicted_90 mutation', 'LGB_predicted_90 artifact',\n",
    "                                              'LGB_predicted_95 mutation', 'LGB_predicted_95 artifact',\n",
    "                                              'LGB_predicted_97.5 mutation', 'LGB_predicted_97.5 artifact',\n",
    "                                              'LGB_predicted_99 mutation', 'LGB_predicted_99 artifact'],\n",
    "                                       columns=['MicroSEC mutation', 'MicroSEC artifact'])\n",
    "\n",
    "conf_table_LGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_true_LGB, y_pred_total_LGB)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "label = 'LightGBM' + ' (AUC={:.3f})'.format(auc(fpr, tpr))\n",
    "plt.plot(fpr, tpr, label=label)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true_GNB, y_pred_total_GNB)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "label = 'Naive Bayes' + ' (AUC={:.3f})'.format(auc(fpr, tpr))\n",
    "plt.plot(fpr, tpr, label=label)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true_LR, y_pred_total_LR)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "label = 'Logistic regression' + ' (AUC={:.3f})'.format(auc(fpr, tpr))\n",
    "plt.plot(fpr, tpr, label=label)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true_DT, y_pred_total_DT)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "label = 'Decision tree classifier' + ' (AUC={:.3f})'.format(auc(fpr, tpr))\n",
    "plt.plot(fpr, tpr, label=label)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true_ADA, y_pred_total_ADA)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "label = 'ADABoost' + ' (AUC={:.3f})'.format(auc(fpr, tpr))\n",
    "plt.plot(fpr, tpr, label=label)\n",
    "\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_pred_total)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "label = 'Random forest classifier' + ' (AUC={:.3f})'.format(auc(fpr, tpr))\n",
    "plt.plot(fpr, tpr, label=label)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curves')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_proba_total)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print (\"Random forest classifier AUC curve : %f\" % roc_auc)\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve: AUC=%0.2f' % roc_auc)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "pd.concat([conf_table, conf_table_LGB], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.feature_importance())\n",
    "lgb.plot_importance(model, height = 0.5, figsize = (8,16))\n",
    "\n",
    "importance = pd.DataFrame(model.feature_importance(), index = X.columns, columns=[\"importance\"])\n",
    "display(importance.sort_values(\"importance\", ascending= False))\n",
    "importance.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = model.predict(X_MSK)\n",
    "df_MSK[y_proba>0.99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance.sort_values(\"importance\", ascending= True).plot.barh(figsize = (8,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance.sort_values(\"importance\", ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network\n",
    "# 5-fold cross validation\n",
    "# Training:Validation:Test = 3:1:1\n",
    "    \n",
    "X_NN = np.array(X)\n",
    "y_NN = np.array(y)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "y_pred_total_NN = []\n",
    "y_proba_total_NN = []\n",
    "y_true_NN = []\n",
    "for train, test in skf.split(X_NN, y_NN):\n",
    "    X_tv = X_NN[train]\n",
    "    X_test = X_NN[test]\n",
    "    y_tv = y_NN[train]\n",
    "    y_test = y_NN[test]\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_tv, y_tv, shuffle=True, test_size=0.25, stratify=y_tv, random_state=100)\n",
    "\n",
    "    inputs = keras.Input(shape=(72,), name='img')\n",
    "    x = layers.Dense(1024, activation='relu')(inputs)\n",
    "    x = layers.Dense(256, activation='relu')(inputs)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.Dense(16, activation='relu')(x)\n",
    "    outputs = layers.Dense(2, activation='softmax')(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name='NN_model')\n",
    "\n",
    "    model.compile(loss='BinaryCrossentropy',\n",
    "                  optimizer=keras.optimizers.RMSprop(),\n",
    "                  metrics=['binary_accuracy'])\n",
    "    early_stopping = EarlyStopping(patience=30, verbose=1) \n",
    "    history = model.fit(X_tv, y_tv,\n",
    "                        batch_size=64,\n",
    "                        epochs=500,\n",
    "                        callbacks=[early_stopping],\n",
    "                        validation_split=0.25)\n",
    "    test_scores = model.evaluate(X_test, y_test, verbose=2)\n",
    "    print('Test loss:', test_scores[0])\n",
    "    print('Test accuracy:', test_scores[1])\n",
    "\n",
    "    y_pred = model_functional.predict(X_test)\n",
    "    y_proba = model_functional.predict(X_test)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_proba[:, 0])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print (\"AUC curve : %f\" % roc_auc)\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC curve: AUC=%0.2f' % roc_auc)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    y_pred_total_NN = np.concatenate([y_pred_total_NN, y_pred[:, 0]])\n",
    "    y_proba_total_NN = np.concatenate([y_proba_total_NN, y_proba[:, 0]])\n",
    "    y_true_NN = np.concatenate([y_true_NN, y_test])\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true_NN, y_proba_total_NN)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print (\"AUC curve : %f\" % roc_auc)\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve: AUC=%0.2f' % roc_auc)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "y_pred_temp_25 = copy.deepcopy(y_proba_total_NN)\n",
    "for i in range(len(y_proba_total_NN)):\n",
    "    if y_proba_total_NN[i]>=0.25:\n",
    "        y_pred_temp_25[i]=1\n",
    "    else:\n",
    "        y_pred_temp_25[i]=0\n",
    "\n",
    "y_pred_temp_50 = copy.deepcopy(y_proba_total_NN)\n",
    "for i in range(len(y_proba_total_NN)):\n",
    "    if y_proba_total_NN[i]>=0.5:\n",
    "        y_pred_temp_50[i]=1\n",
    "    else:\n",
    "        y_pred_temp_50[i]=0\n",
    "\n",
    "y_pred_temp_75 = copy.deepcopy(y_proba_total_NN)\n",
    "for i in range(len(y_proba_total_NN)):\n",
    "    if y_proba_total_NN[i]>=0.75:\n",
    "        y_pred_temp_75[i]=1\n",
    "    else:\n",
    "        y_pred_temp_75[i]=0\n",
    "\n",
    "y_pred_temp_90 = copy.deepcopy(y_proba_total_NN)\n",
    "for i in range(len(y_proba_total_NN)):\n",
    "    if y_proba_total_NN[i]>=0.9:\n",
    "        y_pred_temp_90[i]=1\n",
    "    else:\n",
    "        y_pred_temp_90[i]=0\n",
    "\n",
    "y_pred_temp_95 = copy.deepcopy(y_proba_total_NN)\n",
    "for i in range(len(y_proba_total_NN)):\n",
    "    if y_proba_total_NN[i]>=0.95:\n",
    "        y_pred_temp_95[i]=1\n",
    "    else:\n",
    "        y_pred_temp_95[i]=0\n",
    "\n",
    "y_pred_temp_975 = copy.deepcopy(y_proba_total_NN)\n",
    "for i in range(len(y_proba_total_NN)):\n",
    "    if y_proba_total_NN[i]>=0.975:\n",
    "        y_pred_temp_975[i]=1\n",
    "    else:\n",
    "        y_pred_temp_975[i]=0\n",
    "\n",
    "y_pred_temp_99 = copy.deepcopy(y_proba_total_NN)\n",
    "for i in range(len(y_proba_total_NN)):\n",
    "    if y_proba_total_NN[i]>=0.99:\n",
    "        y_pred_temp_99[i]=1\n",
    "    else:\n",
    "        y_pred_temp_99[i]=0\n",
    "\n",
    "conf_matrix_NN = confusion_matrix(y_pred_temp_25, y_true_NN)\n",
    "conf_matrix_NN = np.concatenate([conf_matrix_NN, confusion_matrix(y_pred_temp_50, y_true_NN)])\n",
    "conf_matrix_NN = np.concatenate([conf_matrix_NN, confusion_matrix(y_pred_temp_75, y_true_NN)])\n",
    "conf_matrix_NN = np.concatenate([conf_matrix_NN, confusion_matrix(y_pred_temp_90, y_true_NN)])\n",
    "conf_matrix_NN = np.concatenate([conf_matrix_NN, confusion_matrix(y_pred_temp_95, y_true_NN)])\n",
    "conf_matrix_NN = np.concatenate([conf_matrix_NN, confusion_matrix(y_pred_temp_975, y_true_NN)])\n",
    "conf_matrix_NN = np.concatenate([conf_matrix_NN, confusion_matrix(y_pred_temp_99, y_true_NN)])\n",
    "\n",
    "conf_table_NN = pd.DataFrame(conf_matrix_NN, index=['NN_predicted_25 mutation', 'NN_predicted_25 artifact', \n",
    "                                              'NN_predicted_50 mutation', 'NN_predicted_50 artifact',\n",
    "                                              'NN_predicted_75 mutation', 'NN_predicted_75 artifact',\n",
    "                                              'NN_predicted_90 mutation', 'NN_predicted_90 artifact',\n",
    "                                              'NN_predicted_95 mutation', 'NN_predicted_95 artifact',\n",
    "                                              'NN_predicted_97.5 mutation', 'NN_predicted_97.5 artifact',\n",
    "                                              'NN_predicted_99 mutation', 'NN_predicted_99 artifact'],\n",
    "                                       columns=['MicroSEC mutation', 'MicroSEC artifact'])\n",
    "\n",
    "conf_table_NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true_LGB, y_proba_total_LGB)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "label = 'LightGBM' + ' (AUC={:.3f})'.format(auc(fpr, tpr))\n",
    "plt.plot(fpr, tpr, label=label)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true_GNB, y_proba_total_GNB)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "label = 'Naive Bayes' + ' (AUC={:.3f})'.format(auc(fpr, tpr))\n",
    "plt.plot(fpr, tpr, label=label)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true_LR, y_proba_total_LR)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "label = 'Logistic regression' + ' (AUC={:.3f})'.format(auc(fpr, tpr))\n",
    "plt.plot(fpr, tpr, label=label)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true_DT, y_proba_total_DT)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "label = 'Decision tree classifier' + ' (AUC={:.3f})'.format(auc(fpr, tpr))\n",
    "plt.plot(fpr, tpr, label=label)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true_ADA, y_proba_total_ADA)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "label = 'ADABoost' + ' (AUC={:.3f})'.format(auc(fpr, tpr))\n",
    "plt.plot(fpr, tpr, label=label)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_proba_total)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "label = 'Random forest classifier' + ' (AUC={:.3f})'.format(auc(fpr, tpr))\n",
    "plt.plot(fpr, tpr, label=label)\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 0.2])\n",
    "plt.ylim([0.8, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curves')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true_LGB, y_proba_total_LGB)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "label = 'LightGBM' + ' (AUC={:.3f})'.format(auc(fpr, tpr))\n",
    "plt.plot(fpr, tpr, label=label)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true_GNB, y_proba_total_GNB)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "label = 'Naive Bayes' + ' (AUC={:.3f})'.format(auc(fpr, tpr))\n",
    "plt.plot(fpr, tpr, label=label)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true_LR, y_proba_total_LR)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "label = 'Logistic regression' + ' (AUC={:.3f})'.format(auc(fpr, tpr))\n",
    "plt.plot(fpr, tpr, label=label)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true_DT, y_proba_total_DT)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "label = 'Decision tree classifier' + ' (AUC={:.3f})'.format(auc(fpr, tpr))\n",
    "plt.plot(fpr, tpr, label=label)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true_ADA, y_proba_total_ADA)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "label = 'ADABoost' + ' (AUC={:.3f})'.format(auc(fpr, tpr))\n",
    "plt.plot(fpr, tpr, label=label)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_proba_total)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "label = 'Random forest classifier' + ' (AUC={:.3f})'.format(auc(fpr, tpr))\n",
    "plt.plot(fpr, tpr, label=label)\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curves')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_DT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
